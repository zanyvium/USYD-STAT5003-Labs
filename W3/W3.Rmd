---
title: "W3 STAT5003 RMD"
author: "Victor Z. Nygaard, vnyg7406"
header-includes:
   - \usepackage[utf8]{inputenc}
   - \usepackage{verbatim}
   - \usepackage[language]{babel}
   - \usepackage[encoding]{inputenc}
   - \usepackage{hyperref}
   - \usepackage{amsmath}
   - \usepackage{mathtools}
   - \usepackage{amssymb}
   - \usepackage{mathtools}
   - \usepackage{nicefrac}
   - \usepackage{fullpage}
   - \usepackage{stmaryrd}
   - \usepackage{aligned-overset}
   - \usepackage{pdfpages}
date: "Last compiled on `r format(Sys.time(), '%d. %B, %Y')`"
# Hvordan får  vi den til at printe February i stedet for februar??????
output: html_document
---

------------------------------------------------------------------------

```{=html}
<!-- RMD tips:
1. CTRL+SHIFT+C RMD-comments-out the selected lines, with in a standard HTML comment-out format. 

2. CTRL+ALT+I inserts a new r codechunck

3. Pressing CTRL+SHIFT+ENTER when over a code chunck gives you a preview of the results of the chunck

4. CTRL+SHIFT+K gives you a preview of the entire resulting HTML file.

5. Note the different results of '#HS 1' and 
'# HS 1' (without the '') in the output

6. It is possible to compile regular R-scripts into Rmd files - this is done by pressing CTRL+SHIFT+K while attending any R-script. <<<- Though this apparently doesn't work for HS Problems.R for some reason!?!?!? ->>>

7. Selective use of the echo=c(...) option within code chuncks allows assignment of a variable, to show the assignment in the knitted document, and showing the value of the assignment seamlessly as well - see HS2.3

8. It is possible to include results of R-analysis such as summary statistics in LaTeX-equations in RMD, see HS2.3

9. Adding fig.align="center" to a code chunk centers any figures generated by the chunck.

9.1 note that properties of codechunks seem casesensitive; fig.align="center" centers a figure, but fig.align="Center" (with capital C) doesn't

10. A new subtitle needs a blank line before itself: 
'works:

#### HS 7
'

'doesn't:
blablabla
#### HS 7
'

'doesn't either:
<!-- blablabla ->
#### HS 7
'
11. Pressing F7 when marking, or hovering over a word will spellcheck the word

12. CTRL + - (minus) zooms out, CTRL + + (plus) zooms in

13. CTRL + D Deletes the current line, or current selection of lines

14. THE FOLLOWING SOURCE EDITOR FOLDING METHODS:
14.1 Collapse current fold: ALT + L
14.1.1: Expand current fold: SHIFT + ALT + L
14.2 Collapse "all" subfolds: ALT + O <- !?!! Note that this leaves a small letter 'o' in the text !!?!
14.2.1 Expand "all" subfolds: SHIFT + ALT + O
14.3 Collapse all other folds: ALT + 0 (zero)

15. SHIFT + ALT + J allows you to jump to specific parts of the document

16. Writing a new line with '...' will cause all previous output to be hidden in the knittet document

17. Writing (q<-5) around R code, will both assign and print the code upon assignment 

18. Note that 'attach' only has the scope of the current R-chunck.

19. One way to get pdf printout is to compile a html-printout, and then, in-browser, 'print' the HTML page as a pdf.

20. CTRL + SHIFT + M gives the pipe operator.

21. Pressing CTRL + F3 searches on the selected word.

22. CTRL
-->
```
<!-- ---?--- How do I create a closeable Rmd section, such that I do not have to scroll through the LaTeX commands each time? - !!! Can be done with '-----' through this also creates a line in the knittet document. -->

<!-- How do I publish and share the HTML as a viewable (and linkable) website - this can be done through github? -->

<!-- How can I share R markdown files such that multiple people can edit them at the same time? -->

<!-- Do we need parindent controls as in LaTeX? -->

<!-- Use of the cache function to reduce recompile times -->

<!-- How to close current subsection with a keyboard shortcut? How to close subsubsections,...? - !!!See RMD tip 14!!! -->

<!-- Chunk naming? -->

<!-- How to define variables such that they have scope within their own ## segment? -->

<!-- How do I delete all non-needed variables for each new section in R??? -->

<!-- LaTeX commands -->

\newcommand{\C}{\mathbb{C}}

<!--- Komplekse tal --->

\newcommand{\R}{\mathbb{R}}

<!--- Reelle tal--->

\newcommand{\Q}{\mathbb{Q}}

<!---Rationelle tal--->

\newcommand{\Z}{\mathbb{Z}}

<!---Hele tal--->

\newcommand{\N}{\mathbb{N}}

<!---Naturlige tal--->

\newcommand{\E}{\mathbb{E}}

<!---mean--->

\newcommand{\F}{\mathbb{F}}

<!---Baggrundsrum sigma-alg--->

\newcommand{\B}{\mathbb{B}}

<!---Borel sigma--->

\newcommand{\K}{\mathbb{K}}

<!---Generel field--->

\newcommand{\RB}{\overline{\R}}

<!---Udvidede reelle tal--->

\newcommand{\ms}[1]{\mathscr{#1}}
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\BR}{\mathcal{B}\left(\R\right)}

<!---Borel på Reelle tal -->

\newcommand{\BRB}{\mathcal{B}\left(\RB\right))}

<!---Borel på udvidede reelle tal -->


\newcommand{\mf}[1]{\mathfrak{#1}} 
\newcommand{\mcG}[2]{\mathcal{#1}^1(#2)} 
\newcommand{\mcGG}[4]{\mathcal{#1}_{#3}^{#2}(#4)}
\newcommand{\GMR}{\left(X,\ms{A},\mu\right)}

<!---Generelt målrum -->

\newcommand{\PBS}{\lrp{\Omega,\F, P}}

<!--- Probability background space -->

\newcommand{\RMR}{\left(\R,\BR, \lambda\right)}

<!---Reelt målrum, m. Borel, og lebesgue mål. -->

<!---L_p spaces on [0,1] with m -->


\newcommand{\Lp}[1]{L_{#1}\lrp{\lrs{0,1},m}} 
\newcommand{\mclxy}{\mc{L}\lrp{X,Y}}
<!---Bounded linear functionals from X to Y -->

\newcommand{\mckxy}{\mc{K}\lrp{X,Y}}

<!---Compact Bounded linear functionals from X to Y -->

\newcommand{\mssr}{\ms{S}(\R)}

<!---The Schwartz space on $\R$ -->

<!---Arrows -->

\newcommand{\ra}{\rightarrow}

<!---Konvergens pil højre -->

\newcommand{\nra}{\nrightarrow}

<!---ikke Konvergens pil højre -->

\newcommand{\la}{\leftarrow}

<!---Konv pil venstre -->

\newcommand{\nla}{\nleftarrow}

<!---ikke Konvergens pil venstre -->

\newcommand{\lra}{\leftrightarrow}

<!---højre venstre pil -->

\newcommand{\nlra}{\nleftrightarrow}

<!---ikke højre venstre pil -->

\newcommand{\hra}{\hookrightarrow}

<!---Injektiv  pil højre -->

\newcommand{\Ra}{\Rightarrow}

<!---Implikations pil højre -->

\newcommand{\Lra}{\Leftrightarrow}

<!---Bi-implikations pil -->

\newcommand{\Uda}{\Updownarrow}

<!---Bi-implikations pil (op og ned) -->

\newcommand{\Da}{\Downarrow}

<!---implikations pil (ned) -->

\newcommand{\rhpu}{\rightharpoonup}

<!---Weak convergence in Hilbert spaces -->

<!-- LHS & RHS calculations -->

\newcommand{\swel}{\overset{\swarrow}{=}}

<!---Continue calculation on left hand side with equality -->

\newcommand{\sweq}{\overset{\swarrow}{\equiv}}

<!---Continue calculation on left hand side with equivalence -->

\newcommand{\seel}{\overset{\searrow}{=}}

<!---Continue calculation on right hand side with equality -->

\newcommand{\seeq}{\overset{\searrow}{\equiv}}

<!---Continue calculation on right hand side with equivalence -->

\newcommand{\inse}{\overset{\cdot}{=}}

<!--- Insert values in calculation -->

\newcommand{\eqd}{\overset{d.}{=}}

\newcommand{\PMX}{\mc{P}\left(X\right)}

<!---Potensmængde af X -->

\newcommand{\comp}{\mathsf{c}}

<!---Set compliment -->

\newcommand{\sm}{\setminus}

<!---mængdedifferens -->

<!--- Parenteser --->

\newcommand{\lrp}[1]{\mathopen{}\left({#1}\right)\mathclose{}}

<!-- \left("STUFF"\right) -->

\newcommand{\lrc}[1]{\mathopen{}\left\{{#1}\right\}\mathclose{}}

<!-- \left\{"STUFF"\right\} -->

\newcommand{\lrs}[1]{\mathopen{}\left[{#1}\right]\mathclose{}}

<!-- \left["STUFF"\right] -->

\newcommand{\lrb}[1]{\mathopen{}\left|{#1}\right|\mathclose{}}

<!-- \left|"STUFF"\right| -->

\newcommand{\inner}[2]{\mathopen{}\left\langle #1, #2 \right\rangle\mathclose{}}

<!-- <\left"STUFF1","STUFF2"\right> -->

\newcommand{\norm}[1]{\mathopen{}\left\lVert#1\right\rVert\mathclose{}}

<!-- \left||"STUFF"\right|| -->

\newcommand{\floor}[1]{\lfloor #1 \rfloor}

<!---Floor function --->

\newcommand{\ceil}[1]{\lceil #1 \rceil}

<!---ceil --->

\newcommand{\FFou}[1]{\mc{F}(#1)}

<!---Fourier Transform notation 1 --->

\newcommand{\Fou}[1]{\widehat{#1}}

<!---Fourier Transform notation 2 --->

<!--- Farver --->

\newcommand{\blue}[1]{\textcolor{blue}{{#1}}}

<!--- Turning text blue --->

\newcommand{\red}[1]{\textcolor{red}{{#1}}}

<!--- Turning text red --->

\newcommand{\green}[1]{\textcolor{green}{{#1}}}

<!--- Turning text green --->

\newcommand{\purple}[1]{\textcolor{purple}{{#1}}}

<!--- Turning text purple --->

\newcommand{\cyan}[1]{\textcolor{cyan}{{#1}}}

<!--- Turning text cyan --->

\newcommand{\orange}[1]{\textcolor{orange}{{#1}}}

<!--- Turning text orange --->

<!--- Oversetting bold accents --->


\newcommand{\boldhat}[1]{\mathbf{\hat{\text{$#1$}}}}
\newcommand{\boldbar}[1]{\mathbf{\bar{\text{$#1$}}}}
\newcommand{\boldtilde}[1]{\mathbf{\tilde{\text{$#1$}}}}
\newcommand{\boldcheck}[1]{\mathbf{\check{\text{$#1$}}}}
\newcommand{\indep}{\perp \!\!\! \perp}

<!---independence --->

\newcommand{\colvec}[1]{\begin{pmatrix}{#1}\end{pmatrix}}

<!-- Begin column vector - Doesn't seem to work with non-column vectors...-->

\newcommand{\nd}[2]{\mc{N}\lrp{{#1},{#2}}}

<!-- Normal distribution -->

\newcommand{\dnd}[2]{\sim\mc{N}\lrp{{#1},{#2}}}

<!-- Distributed as Normal distribution -->

\newcommand{\wnd}[3]{\frac{1}{\sqrt{2\pi\cdot {#3}}}e^{-\frac{1}{2}\frac{\lrp{{#1}-{#2}}^2}{{#3}}}}

<!-- With normal density (prob = #1, mean = #2, variance = #3 -->

\newcommand{\wpd}[2]{\frac{{#2}^{{#1}}\cdot e^{-{#2}}}{{#1}\!}}

<!-- With poisson density (prob = #1, mean = #2 -->

\newcommand{\ep}{\varepsilon}

<!-- \newcommand{\Rlogo}{![](R_logo.png){#id .class width=auto height=16px} } <!-- R logo implemented in text -->

<!-- Image insertion alla LaTeX doesn't seem to work too well..., but inserting the above gives the desired effect. -->

<!--???? \declareMathOperator{\SE}{SE} DOESN'T REALLY SEEM TO WORK????-->

<!-- #librar(reshape2) -->

<!-- #librar(lattice) -->

<!-- #librar(hebin) -->

<!-- #librar(xtable) -->

<!-- #librar(splines) -->

<!-- #librar(survival) -->

<!-- #librar(grid) -->

<!-- #librar(lpSolve) -->

<!-- #librar(unit) -->

<!-- #librar(MASS) #NOTE THAT MASS CAN CAUSE CONFLICTS WITH DPLYR OVER SELECT-FUNCTION -->

<!-- #THOUGHTS: -->
<!-- #4. Can you change the sparse matrix simulator to for example, instead of picking a position & effect combo,  -->
<!-- # and seeing if this works, pick a position, and then try up to 100 different effects, to see if any of these work, -->
<!-- # and then move on to a new position after having tried the 100 different effects? -->
<!-- #5. Could you do a pivot-point determinant calculation based checking of positive definiteness, -->
<!-- # where we start by simulating, for example a fifth of the required support, from the "upper" fifth of the matrix -->
<!-- #6. Could Sparse Matrixes be generated in RCpp? -->
<!-- #7. nlm package. -->
<!-- #8. slim package for Dantzig estimator. -->
<!-- #9. Implement alpha and X0 in MultidimOU. -->
<!-- #10 Size of matrix dependent convergence (dividing by ||A||) -->
<!-- # SHIFT + ALT + DownArrow Copies above line. -->
<!-- #Crossvalidation for choice of lambda: Lowest difference/squared difference -->
<!-- #between training data estimate and Lasso estimate (???) vs. some sort of -->
<!-- #support recovery criteria, or some mix of difference and support recovery.   -->
<!-- #Get MatrixHeatMap to start rowcount at 1, and not 0. -->
<!-- #11. Standardisation for Lasso matrix -->
<!-- #12. LARS for Lasso. -->
<!-- #13. Row and column Sparsity for Sparse matrix generation. -->
<!-- #14. Code commenting. -->
<!-- #15. Rmd. -->
<!-- #16.Plot2D universality -->
<!-- #17.Plot3D Better colours, Bar could be smaller, default zoom and angle, bar should say "time". -->
<!-- #18. Log-transforms for stability? -->
<!-- #Picture compile and save R-document/routine. <- implemented as part of RMD? <- would be ideal. -->
<!-- #One could perhaps optimise the optim functions using apply. -->
<!-- Fix save of 3dplot -->
<!-- nloptr does not do convex methods, is Dantzig convex? -->
<!-- Dantzig via linear programming for convex optimisation with constraints. - see fastlp documentation -->
<!-- For better breaks see https://stackoverflow.com/questions/15622001/how-to-display-only-integer-values-on-an-axis-using-ggplot2 -->
<!-- MatrixHeatMap limits = min and max, or symmetric instead? -->
<!-- Check for positive mindiag argument to SparseMat? -->
<!-- Offdiagonal size options for SparseMat? -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(fig.align = 'center')
library(tidyverse)
library(gridExtra)
theme_set(theme_minimal())
library(MASS) #Has a conflict with dplyr regarding select.
library(reshape2)
#library(plot.matrix) 
library(Matrix)
library(expm)
#library(plotly) #for 3D plotting
#library(reticulate) #Used for saving plotly images
#library(nloptr) #optimisation
#library(lpSolve) #linear programming
library(microbenchmark)
library(scales) #used for log trans of ggplot
#library(stats4) #mle and stuff
set.seed(314)

varnametotext <- function(v){
   deparse(substitute(v))
}
Stdresplot <- function(model, main = paste("(Estimate, Std. Res.)-plot of", deparse(substitute(model))), ylab ="Standardized residuals", ...) {
 fit <- fitted(model)
 rst <- rstandard(model)
 qplot(fit, rst, main = main, ylab = ylab, ylim = c(-max(3.2,max(abs(rst))), max(3.2,max(abs(rst)))) )+geom_hline(yintercept = 0) #Largest symmetric interval (around 0) of (-3.2,3.2) or (-largest absolute rst, largest absolute rst)
}
QQplotdraw <- function(model, main = paste("Normal QQ-plot of", deparse(substitute(model))), xlab = "Theoretical Quantiles", ylab ="Sample Quantiles", ...) {
   rst <- rstandard(model)
   #dataname <- getCall(lm_LT)$data
   ggplot(data = eval(getCall(model)$data), main = main, xlab = xlab, ylab = ylab) + geom_qq() + geom_qq_line() + aes(sample = rst)
} #main, xlab, ylab call do not work for some reason
StdresQQPlot <- function(model,...) {
   p1 <- Stdresplot(model,...)
   p2 <- QQplotdraw(model,...)
   #library(gridExtra)
   grid.arrange(p1,p2, ncol = 2)
}
```

# 1
We may simulate the samples of Gaussian variables and plot the data on density scale as such:
```{r}
n <- 10^2
mu <- 10
sigma <- 10
gau <- rnorm(n = n, mean = mu, sd = sigma)
gau %>% as.data.frame %>% ggplot() + geom_histogram(bins = 20, aes(x = gau, y = ..density..)) + xlab("N(10,10^2) Outcomes")
```

We note that the above simulation of Gaussian variables was carried out using a default seed of $314$ implemented in the setup chuck of my RMD template.
Setting a new seed, we may simulate new data:
```{r}
stu_id <- 520540446
set.seed(stu_id)
gau <- rnorm(n, mu,sigma)
rm(.Random.seed, envir=globalenv()) #reset seed
set.seed(stu_id) #set seed again.
#simulate again,
#test for whether all values of gau == rnorm(10^2, 10, 10) are T
identical(gau, rnorm(n, mu, sigma)) 
```
We will simulate $100$ iid. outcomes of $\nd{\mu}{10^2}$ for each of $\mu = 1,2,\ldots, 20$ 
```{r}
muVec <- seq(1,20,1)
normalMatrix <- matrix(NA, n, length(muVec)) 
#!!!careful with scoping here, calling for (mu in muVec, changes the global mu for some reason)
for (m in muVec) {
   normalMatrix[,m] <- rnorm(n, m, sigma)
}
```

For each $\mu$ we calculate the log-likelihood that this iid data is derived from $\nd{10}{10}.$ We do this two different ways, as shown:
```{r}
logLike <- apply(apply(normalMatrix,2,dnorm, mean = mu, sd = sigma, log = T), 2, sum) #using dnorm

#using loglikelihood function
f <- function(x, mu, sigma) { 
   -n/2*log(2*pi*sigma^2)-1/(2*sigma^2)*sum((x-mu)^2)
}
identical(logLike, apply(normalMatrix, 2, f, mu = 10, sigma = 10)) #is the result the same? -> 'No'

#really? The results are not the same? 
max(logLike-apply(normalMatrix, 2, f, mu = 10, sigma = 10)) # they ARE the same up to numerical error.
```

In particular, for $\mu = 8$ we get a loglikelihood of `r logLike[8]`. We may also plot the loglikelihoods:
```{r}
muLogLikeDf <- data.frame(mu = muVec,logLikelihood = logLike)
muLogLikeDf %>% ggplot() + geom_point(aes(x = mu, y = logLikelihood))
```

Note that based on the plot, we get the maximum loglikelihood value at $\mu=9$ for $n=100$ though we know from general theory that likelihood will guess correctly asymptotically.

# 2
We load in the data:
```{r}
height <- read_table("../Data/height.txt")
head(height)
```

We plot the data in a histogram for $5, 10, 20, 30$ bins respectively.
```{r}
p <- height %>% dplyr::select(Height_m) %>% ggplot(aes(x = Height_m, y = ..density..)) + xlab("Height") + ylab("Density")
p1 <- p + geom_histogram(bins = 30, colour = "black", fill = "yellow") + ggtitle("Height, Density. 30 bins.")
p2 <- p + geom_histogram(bins = 5, colour = "black", fill = "yellow") + ggtitle("Height, Density. 5 bins.")
p3 <- p + geom_histogram(bins = 10, colour = "black", fill = "yellow") + ggtitle("Height, Density. 10 bins.")
p4 <- p + geom_histogram(bins = 20, colour = "black", fill = "yellow") + ggtitle("Height, Density. 20 bins.")
grid.arrange(p2,p3,p4,p1,ncol = 2)
```

We use `density` to do kernel density estimation
```{r}
#?density #checking info on the density function
gKernel <- height %>% dplyr::select(Height_m) %>% as.matrix %>% as.numeric %>% density(kernel = "gaussian")
eKernel <- height %>% dplyr::select(Height_m) %>% as.matrix %>% as.numeric %>% density(kernel = "epanechnikov")
tKernel <- height %>% dplyr::select(Height_m) %>% as.matrix %>% as.numeric %>% density(kernel = "triangular")
```

We may plot the results:
```{r}
Kernel_df <- function(K) data.frame(x = K$x, y = K$y)
empty_p <- ggplot() + xlab("Height") + ylab("Density")
g_plot <- empty_p + geom_line(Kernel_df(gKernel), mapping = aes(x = x, y = y), colour = "cyan", size = 0.8) + ggtitle("Gaussian Kernel")
e_plot <- empty_p + geom_line(Kernel_df(eKernel), mapping = aes(x = x, y = y), colour = "maroon", size = 0.8) + ggtitle("Epanechnikov Kernel")
t_plot <- empty_p + geom_line(Kernel_df(tKernel), mapping = aes(x = x, y = y), colour = "hotpink", size = 0.8) + ggtitle("Triangular Kernel")

grid.arrange(g_plot, e_plot, t_plot, ncol = 3)
```

We may also plot the estimated curves together on the same plot, as well as with the data, this time using `stat_density`'s kernel function with default parameters.
```{r}
p1 + geom_density(kernel = "gaussian", colour = "cyan", size = 0.8, alpha = 0.5, show.legend = T) +
   geom_density(kernel = "epanechnikov", colour = "maroon", size = 0.8, alpha = 0.5, show.legend = T) +
   geom_density(kernel = "triangular", colour = "hotpink", size = 0.8, alpha = 0.5, show.legend = T) + ggtitle("Height, Density, 30 Bins, Kernel Estimates")
```


We may compute an estimate of the probability that a person is higher than $1.7m$ using each of the kernel density estimators:
```{r}
integrate(approxfun(gKernel), 1.7, max(gKernel$x))
integrate(approxfun(eKernel), 1.7, max(eKernel$x))
integrate(approxfun(tKernel), 1.7, max(tKernel$x))
```
and compare this to the empirical estimate
```{r}
mean(height$Height_m>1.7)
```

We may load in the `stats4` library.
```{r}
library(stats4)
ff <- function(mu,sigma) {
   return(-f(height$Height_m, mu, sigma))
}
mle_fit <- mle(ff, start = list(mu = 1, sigma = 1))
coef(mle_fit)
```

Under the iid normality assumption implicitly implemented in using `mle` on `ff`, `mle` optimises `ff` for the parameters `mu` and `sigma`, starting in `mu = 1` and `sigma = 1`. The resulting MLE estimates for $\mu$ and $\sigma$ are `coef(mle_fit)[1]` and `coef(mle_fit)[2]`, as shown above.

# 3

We simulate $100$ values from $\nd{0}{1}$ and write our ISE-calculating function `ISECalc` that takes in the required parameters; the data to 'train' the kernel, the bandwidth $h$ to be used in the kernel-specification, the desired kernel, and the range over which to calculate the ISE. The function outputs an ISE-estimate.
```{r}
stdNorm <- rnorm(100)
ISECalc <- function(data, h, f, kernel = "triangular", range = range(data)) {
   kDens <- density(data, bw = h, kernel = kernel, n = 512, from = range[1], to = range[2])
   fapp <- approxfun(kDens)
   fDiffSq <- function(x) (fapp(x)-f(x))^2
   return(integrate(fDiffSq, range[1], range[2])[[1]])
}
```

Based on this function, we may calculate the ISE for a range of $h$ values from $0.05$ up to $2$, as specified `hVec` below.
In our example, we will use the triangular kernel. We note the restriction of the integration range from $-\infty, \infty$ to $-3,3$ as this is were the far majority of support lies for standard normal random variables. From this, we may plot the resulting relation as a scatterplot. We have high-lighted the minimal $h$ value
```{r}
hVec <- seq(0.05,2,0.025)
ISEVal <- c()
for (i in 1:length(hVec)) {
   ISEVal[i] <- ISECalc(stdNorm, hVec[i], dnorm, "triangular", c(-3, 3))
}
ggplot(data.frame(h_Values = hVec, ISE_Values = ISEVal), aes(x = h_Values, y = ISE_Values)) +
   geom_point() +
   ggtitle("Estimated N(0,1) ISE-error of triangular kernel app. as a function of bandwidth(h)") +
   geom_vline(aes(xintercept = hVec[which.min(ISEVal)]), linetype = "dashed", size = 1, colour = "hotpink")
```

Loading in the $\text{argmin}$ value of $h,$ we may plot the estimated triangular kernel density against the true standard normal one
```{r}
h05_tdens <- density(stdNorm, bw = hVec[which.min(ISEVal)], n = 512, kernel = "triangular")

kernel_stdnormal_df <- data.frame(simVal = seq(-3,3,0.01), densVal = dnorm(seq(-3,3,0.01)),
                                  Density_type = rep("std_normal",length(seq(-3,3,0.01)))) %>%
   rbind(data.frame(simVal = h05_tdens$x, densVal = h05_tdens$y,
                    Density_type = rep("triangular_kernel", length(h05_tdens$y))))
kernel_stdnormal_df %>% ggplot(aes(x = simVal, y = densVal, colour = Density_type)) + geom_line(size = 1.2, alpha = 0.6) + labs(x = "N(0,1) outcome", y = "Density", title = "True N(0,1) and est. triangular kernel density for 'optimal' bandwidth h = 0.5")
```

We see that the kernel mimics the standard normal density rather well, as based on $100$ samples.

While the method employed above to find an optimal bandwidth value is superior to guessing, or going with a fixed default one may also note that `?stats::bw.ucv`, `?stats::bw.nrd0(x)`,... reveal that there are alternative methods of choosing a default bandwidth value that are smarter than picking some fixed value. Attempting with the biased Gaussian cross-validated `bw.bcv` we may plot the result
```{r}
bw <- bw.bcv(height$Height_m) 
bwDensity <- density(height$Height_m, bw = bw, kernel = "gaussian")
bwDensity_df <- data.frame(x = bwDensity$x, y = bwDensity$y)
p1 + geom_line(data = bwDensity_df, aes(x=x, y=y),colour = "darkblue", size = 1, linetype = "dashed") + labs(title = "Height, bw.bcw adjusted Gaussian kernel density estimate", x = "Height", y = "Density")
```

<!-- #p1 + geom_line(data = bwDensity_df, aes(x=x, y=y, linetype = "dashed"), size = 1) + labs(title = "Height, bw.bcw adjusted gaussian kernel density estimate", x = "Height", y = "Density") -->
































































































































