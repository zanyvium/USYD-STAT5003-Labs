---
title: "Computer Test"
subtitle: "STAT5003 Semester 2, 2021"
date: "14th september, 2022"
author: "Victor 520540446 - TEST STUDENT"
header-includes:
   - \usepackage[utf8]{inputenc}
   - \usepackage{verbatim}
   - \usepackage[language]{babel}
   - \usepackage[encoding]{inputenc}
   - \usepackage{hyperref}
   - \usepackage{amsmath}
   - \usepackage{mathtools}
   - \usepackage{amssymb}
   - \usepackage{mathtools}
   - \usepackage{nicefrac}
   - \usepackage{fullpage}
   - \usepackage{stmaryrd}
   - \usepackage{aligned-overset}
   - \usepackage{pdfpages}
# Hvordan får  vi den til at printe February i stedet for februar??????
output: html_document
---

------------------------------------------------------------------------

```{=html}
<!-- RMD tips:
1. CTRL+SHIFT+C RMD-comments-out the selected lines, with in a standard HTML comment-out format. 

2. CTRL+ALT+I inserts a new r codechunck

3. Pressing CTRL+SHIFT+ENTER when over a code chunck gives you a preview of the results of the chunck

4. CTRL+SHIFT+K gives you a preview of the entire resulting HTML file.

5. Note the different results of '#HS 1' and 
'# HS 1' (without the '') in the output

6. It is possible to compile regular R-scripts into Rmd files - this is done by pressing CTRL+SHIFT+K while attending any R-script. <<<- Though this apparently doesn't work for HS Problems.R for some reason!?!?!? ->>>

7. Selective use of the echo=c(...) option within code chuncks allows assignment of a variable, to show the assignment in the knitted document, and showing the value of the assignment seamlessly as well - see HS2.3

8. It is possible to include results of R-analysis such as summary statistics in LaTeX-equations in RMD, see HS2.3

9. Adding fig.align="center" to a code chunk centers any figures generated by the chunck.

9.1 note that properties of codechunks seem casesensitive; fig.align="center" centers a figure, but fig.align="Center" (with capital C) doesn't

10. A new subtitle needs a blank line before itself: 
'works:

#### HS 7
'

'doesn't:
blablabla
#### HS 7
'

'doesn't either:
<!-- blablabla ->
#### HS 7
'
11. Pressing F7 when marking, or hovering over a word will spellcheck the word

12. CTRL + - (minus) zooms out, CTRL + + (plus) zooms in

13. CTRL + D Deletes the current line, or current selection of lines

14. THE FOLLOWING SOURCE EDITOR FOLDING METHODS:
14.1 Collapse current fold: ALT + L
14.1.1: Expand current fold: SHIFT + ALT + L
14.2 Collapse "all" subfolds: ALT + O <- !?!! Note that this leaves a small letter 'o' in the text !!?!
14.2.1 Expand "all" subfolds: SHIFT + ALT + O
14.3 Collapse all other folds: ALT + 0 (zero)

15. SHIFT + ALT + J allows you to jump to specific parts of the document

16. Writing a new line with '...' will cause all previous output to be hidden in the knittet document

17. Writing (q<-5) around R code, will both assign and print the code upon assignment 

18. Note that 'attach' only has the scope of the current R-chunck.

19. One way to get pdf printout is to compile a html-printout, and then, in-browser, 'print' the HTML page as a pdf.

20. CTRL + SHIFT + M gives the pipe operator.

21. Pressing CTRL + F3 searches on the selected word.

22. CTRL

23. ALT + SHIFT + DOWN copies a line to below.
-->
```
<!-- ---?--- How do I create a closeable Rmd section, such that I do not have to scroll through the LaTeX commands each time? - !!! Can be done with '-----' through this also creates a line in the knittet document. -->

<!-- How do I publish and share the HTML as a viewable (and linkable) website - this can be done through github? -->

<!-- How can I share R markdown files such that multiple people can edit them at the same time? -->

<!-- Do we need parindent controls as in LaTeX? -->

<!-- Use of the cache function to reduce recompile times -->

<!-- How to close current subsection with a keyboard shortcut? How to close subsubsections,...? - !!!See RMD tip 14!!! -->

<!-- Chunk naming? -->

<!-- How to define variables such that they have scope within their own ## segment? -->

<!-- How do I delete all non-needed variables for each new section in R??? -->

<!-- LaTeX commands -->

\newcommand{\C}{\mathbb{C}}

<!--- Komplekse tal --->

\newcommand{\R}{\mathbb{R}}

<!--- Reelle tal--->

\newcommand{\Q}{\mathbb{Q}}

<!---Rationelle tal--->

\newcommand{\Z}{\mathbb{Z}}

<!---Hele tal--->

\newcommand{\N}{\mathbb{N}}

<!---Naturlige tal--->

\newcommand{\E}{\mathbb{E}}

<!---mean--->

\newcommand{\F}{\mathbb{F}}

<!---Baggrundsrum sigma-alg--->

\newcommand{\B}{\mathbb{B}}

<!---Borel sigma--->

\newcommand{\K}{\mathbb{K}}

<!---Generel field--->

\newcommand{\RB}{\overline{\R}}

<!---Udvidede reelle tal--->

\newcommand{\ms}[1]{\mathscr{#1}}
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\BR}{\mathcal{B}\left(\R\right)}

<!---Borel på Reelle tal -->

\newcommand{\BRB}{\mathcal{B}\left(\RB\right))}

<!---Borel på udvidede reelle tal -->


\newcommand{\mf}[1]{\mathfrak{#1}} 
\newcommand{\mcG}[2]{\mathcal{#1}^1(#2)} 
\newcommand{\mcGG}[4]{\mathcal{#1}_{#3}^{#2}(#4)}
\newcommand{\GMR}{\left(X,\ms{A},\mu\right)}

<!---Generelt målrum -->

\newcommand{\PBS}{\lrp{\Omega,\F, P}}

<!--- Probability background space -->

\newcommand{\RMR}{\left(\R,\BR, \lambda\right)}

<!---Reelt målrum, m. Borel, og lebesgue mål. -->

<!---L_p spaces on [0,1] with m -->


\newcommand{\Lp}[1]{L_{#1}\lrp{\lrs{0,1},m}} 
\newcommand{\mclxy}{\mc{L}\lrp{X,Y}}
<!---Bounded linear functionals from X to Y -->

\newcommand{\mckxy}{\mc{K}\lrp{X,Y}}

<!---Compact Bounded linear functionals from X to Y -->

\newcommand{\mssr}{\ms{S}(\R)}

<!---The Schwartz space on $\R$ -->

<!---Arrows -->

\newcommand{\ra}{\rightarrow}

<!---Konvergens pil højre -->

\newcommand{\nra}{\nrightarrow}

<!---ikke Konvergens pil højre -->

\newcommand{\la}{\leftarrow}

<!---Konv pil venstre -->

\newcommand{\nla}{\nleftarrow}

<!---ikke Konvergens pil venstre -->

\newcommand{\lra}{\leftrightarrow}

<!---højre venstre pil -->

\newcommand{\nlra}{\nleftrightarrow}

<!---ikke højre venstre pil -->

\newcommand{\hra}{\hookrightarrow}

<!---Injektiv  pil højre -->

\newcommand{\Ra}{\Rightarrow}

<!---Implikations pil højre -->

\newcommand{\Lra}{\Leftrightarrow}

<!---Bi-implikations pil -->

\newcommand{\Uda}{\Updownarrow}

<!---Bi-implikations pil (op og ned) -->

\newcommand{\Da}{\Downarrow}

<!---implikations pil (ned) -->

\newcommand{\rhpu}{\rightharpoonup}

<!---Weak convergence in Hilbert spaces -->

<!-- LHS & RHS calculations -->

\newcommand{\swel}{\overset{\swarrow}{=}}

<!---Continue calculation on left hand side with equality -->

\newcommand{\sweq}{\overset{\swarrow}{\equiv}}

<!---Continue calculation on left hand side with equivalence -->

\newcommand{\seel}{\overset{\searrow}{=}}

<!---Continue calculation on right hand side with equality -->

\newcommand{\seeq}{\overset{\searrow}{\equiv}}

<!---Continue calculation on right hand side with equivalence -->

\newcommand{\inse}{\overset{\cdot}{=}}

<!--- Insert values in calculation -->

\newcommand{\eqd}{\overset{d.}{=}}

\newcommand{\PMX}{\mc{P}\left(X\right)}

<!---Potensmængde af X -->

\newcommand{\comp}{\mathsf{c}}

<!---Set compliment -->

\newcommand{\sm}{\setminus}

<!---mængdedifferens -->

<!--- Parenteser --->

\newcommand{\lrp}[1]{\mathopen{}\left({#1}\right)\mathclose{}}

<!-- \left("STUFF"\right) -->

\newcommand{\lrc}[1]{\mathopen{}\left\{{#1}\right\}\mathclose{}}

<!-- \left\{"STUFF"\right\} -->

\newcommand{\lrs}[1]{\mathopen{}\left[{#1}\right]\mathclose{}}

<!-- \left["STUFF"\right] -->

\newcommand{\lrb}[1]{\mathopen{}\left|{#1}\right|\mathclose{}}

<!-- \left|"STUFF"\right| -->

\newcommand{\inner}[2]{\mathopen{}\left\langle #1, #2 \right\rangle\mathclose{}}

<!-- <\left"STUFF1","STUFF2"\right> -->

\newcommand{\norm}[1]{\mathopen{}\left\lVert#1\right\rVert\mathclose{}}

<!-- \left||"STUFF"\right|| -->

\newcommand{\floor}[1]{\lfloor #1 \rfloor}

<!---Floor function --->

\newcommand{\ceil}[1]{\lceil #1 \rceil}

<!---ceil --->

\newcommand{\FFou}[1]{\mc{F}(#1)}

<!---Fourier Transform notation 1 --->

\newcommand{\Fou}[1]{\widehat{#1}}

<!---Fourier Transform notation 2 --->

<!--- Farver --->

\newcommand{\blue}[1]{\textcolor{blue}{{#1}}}

<!--- Turning text blue --->

\newcommand{\red}[1]{\textcolor{red}{{#1}}}

<!--- Turning text red --->

\newcommand{\green}[1]{\textcolor{green}{{#1}}}

<!--- Turning text green --->

\newcommand{\purple}[1]{\textcolor{purple}{{#1}}}

<!--- Turning text purple --->

\newcommand{\cyan}[1]{\textcolor{cyan}{{#1}}}

<!--- Turning text cyan --->

\newcommand{\orange}[1]{\textcolor{orange}{{#1}}}

<!--- Turning text orange --->

<!--- Oversetting bold accents --->


\newcommand{\boldhat}[1]{\mathbf{\hat{\text{$#1$}}}}
\newcommand{\boldbar}[1]{\mathbf{\bar{\text{$#1$}}}}
\newcommand{\boldtilde}[1]{\mathbf{\tilde{\text{$#1$}}}}
\newcommand{\boldcheck}[1]{\mathbf{\check{\text{$#1$}}}}
\newcommand{\indep}{\perp \!\!\! \perp}

<!---independence --->

\newcommand{\colvec}[1]{\begin{pmatrix}{#1}\end{pmatrix}}

<!-- Begin column vector - Doesn't seem to work with non-column vectors...-->

\newcommand{\nd}[2]{\mc{N}\lrp{{#1},{#2}}}

<!-- Normal distribution -->

\newcommand{\dnd}[2]{\sim\mc{N}\lrp{{#1},{#2}}}

<!-- Distributed as Normal distribution -->

\newcommand{\wnd}[3]{\frac{1}{\sqrt{2\pi\cdot {#3}}}e^{-\frac{1}{2}\frac{\lrp{{#1}-{#2}}^2}{{#3}}}}

<!-- With normal density (prob = #1, mean = #2, variance = #3 -->

\newcommand{\wpd}[2]{\frac{{#2}^{{#1}}\cdot e^{-{#2}}}{{#1}\!}}

<!-- With poisson density (prob = #1, mean = #2 -->

\newcommand{\ep}{\varepsilon}

<!-- \newcommand{\Rlogo}{![](R_logo.png){#id .class width=auto height=16px} } <!-- R logo implemented in text -->

<!-- Image insertion alla LaTeX doesn't seem to work too well..., but inserting the above gives the desired effect. -->

<!--???? \declareMathOperator{\SE}{SE} DOESN'T REALLY SEEM TO WORK????-->

<!-- #librar(reshape2) -->

<!-- #librar(lattice) -->

<!-- #librar(hebin) -->

<!-- #librar(xtable) -->

<!-- #librar(splines) -->

<!-- #librar(survival) -->

<!-- #librar(grid) -->

<!-- #librar(lpSolve) -->

<!-- #librar(unit) -->

<!-- #librar(MASS) #NOTE THAT MASS CAN CAUSE CONFLICTS WITH DPLYR OVER SELECT-FUNCTION -->




<!-- # !!!dplyr::select(indNoNA, where(is.numeric)) -->
<!-- indNoNA <- indians %>% drop_na() %>% mutate(across(c(pregnant:insulin,age), as.integer)) -->
<!-- install.packages("ggrepel") -->
<!-- !!! ```{r} -->
<!-- gdf <- -->
<!--   tibble(g = c(1, 1, 2, 3), v1 = 10:13, v2 = 20:23) %>% -->
<!--   group_by(g) -->
<!-- gdf -->

<!-- set.seed(1) -->

<!-- # Outside: 1 normal variate -->
<!-- n <- rnorm(1) -->
<!-- n -->
<!-- gdf %>% mutate(across(v1:v2, ~ .x + n)) -->
<!-- ``` -->

<!-- !!! ```{r} -->
<!-- ? family -->
<!-- ``` -->

<!-- !!! # ```{r} -->
<!-- # ifelse -->
<!-- # ``` -->

<!-- # ```{r} -->
<!-- # df <- df %>% -->
<!-- #   mutate(n = row_number()) %>% #create row number if you dont have one -->
<!-- #   select(n, everything()) # put 'n' at the front of the dataset -->
<!-- # train <- df %>% -->
<!-- #   group_by(var1, var2) %>% #any number of variables you wish to partition by proportionally -->
<!-- #   sample_frac(.7) # '.7' is the proportion of the original df you wish to sample -->
<!-- # test <- anti_join(df, train) # creates test dataframe with those observations not in 'train.' -->
<!-- # ``` -->


<!-- ```{r} -->
<!-- RColorBrewer::brewer.pal(10, "Set1") #but then try with 9 -->
<!-- ``` -->

<!-- #!!! NOTE THAT sample does not work well together with dataframes!!!! -->


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(fig.align = 'center')
Sys.setenv("TZ" = "Australia/Sydney")
library(tidyverse)
library(gridExtra)
theme_set(theme_minimal())
library(MASS) #Has a conflict with dplyr regarding select.
library(reshape2)
library(caret) #Used for Machine Learning
#library(plot.matrix) 
library(Matrix)
library(expm)
#library(plotly) #for 3D plotting
#library(reticulate) #Used for saving plotly images
#library(nloptr) #optimisation
#library(lpSolve) #linear programming
library(microbenchmark)
library(scales) #used for log trans of ggplot
#library(stats4) #mle and stuff
#set.seed(314)

varnametotext <- function(v){
   deparse(substitute(v))
}
Stdresplot <- function(model, main = paste("(Estimate, Std. Res.)-plot of", deparse(substitute(model))), ylab ="Standardized residuals", ...) {
 fit <- fitted(model)
 rst <- rstandard(model)
 qplot(fit, rst, main = main, ylab = ylab, ylim = c(-max(3.2,max(abs(rst))), max(3.2,max(abs(rst)))) )+geom_hline(yintercept = 0) #Largest symmetric interval (around 0) of (-3.2,3.2) or (-largest absolute rst, largest absolute rst)
}
QQplotdraw <- function(model, main = paste("Normal QQ-plot of", deparse(substitute(model))), xlab = "Theoretical Quantiles", ylab ="Sample Quantiles", ...) {
   rst <- rstandard(model)
   #dataname <- getCall(lm_LT)$data
   ggplot(data = eval(getCall(model)$data), main = main, xlab = xlab, ylab = ylab) + geom_qq() + geom_qq_line() + aes(sample = rst)
} #main, xlab, ylab call do not work for some reason
StdresQQPlot <- function(model,...) {
   p1 <- Stdresplot(model,...)
   p2 <- QQplotdraw(model,...)
   #library(gridExtra)
   grid.arrange(p1,p2, ncol = 2)
}
```


This document was compiled on: `r format(Sys.time())`

### Instructions

1. This is an open book quiz, and you are allowed to search the Internet and the course webpage to access any descriptions and `R` code that may help you to solve the questions. However, be mindful that searching for the solution may take longer than you may be capable of doing by youself. Keep track of your time regularly.
1. Place your answers in the code chunk spaces provided adding typed comments below the code chunks as necessary if required (some questions may ask you to interpret your output).
1. We suggest you begin by **knitting** (compiling) the Rmd to make sure the template works on your system.
1. It's a good idea to submit your work **regularly** - if you end up submitting the final version late, the marker can go back and mark only the on-time submission.
1. For time management it is suggested you set the alarm on your phone and give yourself plenty of time for submission.

### Question 1

Consider the number of Covid cases in both NSW and VIC since NSW (Greater Sydney) entered the lockdown due to the Delta variant starting on 26th June 2021. The full data is available on github and can be shared after the assessment. The goal of this question is to compare the growth in the number of cases between NSW and VIC since their most recent lockdown restrictions began. For NSW that was 26th June 2021. For VIC, assume this date to be 5th August 2021. The relevant data for this question has been saved into a `rds` file that contains case counts for NSW and VIC respectively. The data can be loaded with the following command.
```{r data-input, echo = TRUE}
vic.delta.wave <- readRDS("S2-2021-Q1-vic-delta-wave.rds")
nsw.delta.wave <- readRDS("S2-2021-Q1-nsw-delta-wave.rds")
```
Using this data, answer the following questions.

a. **[3 marks]** Determine the structure and dimension of the `vic.delta.wave` and `nsw.delta.wave`.

```{r q1a}
# Input your answer here

#structure and dim of vic
str(vic.delta.wave)
dim(vic.delta.wave)


#structure and dim of nsw
str(nsw.delta.wave)
dim(nsw.delta.wave)

```
b. **[3 marks]** Using `R` code and the data provided, determine the number of days each state has been in their most recent lockdown. To do this, remove the days from the VIC dataset that occurred **before** 5th August 2021. Note marks will be awarded for both the correct number of days for each state and for a correct R code statement to generate that value. __Hint__: The `subset` or an equivalent command is useful here. The `date` columns have the `Date` data type and date comparisons can be made by converting a string to a `Date` with `as.Date`. E.g. `date > as.Date("2020-12-31")` will return `TRUE` for any values in `date` after 31st December 2020 and `FALSE` otherwise.

Note that the problem is stated in an ambiguous, and non-sensical manner, assuming various outside info available to students such as when the lockdown ended. Evenmoreso, the most likely 'fished after' method, of subsetting the data, and recording the number of entries in the subset data is equally as non-sensical as we could have non-recorded or skipped dates in the dataset, which the 'fished after method' does not account for. Nontheless, the 'fished after' a proper alternative to answering the question, given that we assume that all dates after the lockdown dates for each state was in lockdown
```{r q1b}
 # nonsensical VIC & NSW
vic_lockdown = as.Date("2021-08-05")
nsw_lockdown = as.Date("2021-06-26")

vic.delta.wave %>% subset(date >= vic_lockdown) %>% nrow()
nsw.delta.wave %>% subset(date >= nsw_lockdown) %>% nrow()

difftime(max(vic.delta.wave$date), vic_lockdown, units = "days") +1
difftime(max(nsw.delta.wave$date), nsw_lockdown, units = "days") +1 #+1 for inclusive date counting (two consequtive days count as two days, not 1)
```
c. **[2 marks]** Add two new columns to each dataset.
    - `days.in.lockdown`: a simple integer counting the number of days the state started the latest lockdown (the first day of lockdown will count as zero here, e.g. `days.in.lockdown` should be zero for NSW and VIC on 26th June and 5th August respectively).
    - `state`: A simple label for each of the two data.frames with the repeated character of `"NSW"` or `"VIC"` for the New South Wales and Victoria datasets respectively.

```{r q1c}
# Input your answer here
#<- the below is also not a robust solution as dates could be not-sorted, non-the-less
vic.delta.wave <- vic.delta.wave %>% mutate(days.in.lockdown = c(rep(0,40), 1:48), state = rep("VIC", 88))
nsw.delta.wave <- nsw.delta.wave %>% mutate(days.in.lockdown = 1:88, state = rep("NSW", 88))

```
d. **[1 mark]** Merge the two datasets into a combined `data.frame`, joining by **row** (Hint: `rbind` is useful for this purpose). 

```{r q1d}
# Input your answer here
states_combined <- nsw.delta.wave %>% bind_rows(vic.delta.wave)
```

e. **[8 marks]** Using your merged data set above or otherwise, create a **scatterplot** showing the number of covid cases experienced by the two states. In your answer
    - show the number of cases on the y-axis
    - show the days in the latest lockdown on the x-axis (not the Date Variable)
    - add a separate nonparametric smoother for each of the NSW and VIC.
    - use appropriate informative labels and a legend
    - using your plot, comment on whether the delta outbreak is growing faster or slower in VIC compared to NSW.

```{r q1e}
# Input your answer here
states_combined %>% ggplot(mapping = aes(x = days.in.lockdown, y = confirmed, colour = state)) + geom_point() + geom_smooth()
```

Based on the plot, it seem that the number of confirmed cases in each lockdown period was approximately the same until about $25$ days in, where Victoria's number of confirmed cases seems to take off.

### Question 2

For this question, the same data as Question 1 is used but focuses on the NSW case numbers from day 50 to 75 of their lockdown. This data is provided in the RDS file below. A colleague mentions that this data looks linear over this time periods and wants to statistically examine a model.

```{r q2-file}
q2.dat <- readRDS("S2-2021-Q2.rds")
```

a. **[4 marks]** Compute a linear regression of the confirmed covid cases (outcome) against the days in lockdown (feature). In your answer
    - plot the data with a scatterplot and the least squares regression line.
    - Use informative axis labels
    - compute and print the standard error of the slope coefficient.
```{r q2a}
# Input your answer here
head(q2.dat)
q2.dat
nsw_linmod <- lm(confirmed ~ days.in.lockdown, data = q2.dat)
q2.dat %>% ggplot(mapping = aes(x = days.in.lockdown, y = confirmed)) + geom_point() + geom_abline(slope = coef(nsw_linmod)[[2]], intercept = coef(nsw_linmod)[[1]])
coef(nsw_linmod)
(org_lin <- summary(nsw_linmod)$coef[2,1:2]) #estimate and standard error of the slope coefficient
```

b. **[7 marks]** Write your __own__ function in `R` that computes the bootstrapped estimate of the standard error of the slope coefficient of such a linear regression. Minimal marks will be awarded for a correct answer that uses an external package at this step. The answer should be written in `base` R code. In your answer,
    * Write a function called `simple_regression_from_data` that takes one argument, a `data.frame` with 2 columns with variables suitable for a linear regression. It computes a linear regression of the second column (outcome) against the first column (feature) and returns just the regression slope coefficient (not the intercept).
    * Compute bootstrap samples of the data. Use `B = 26` bootstrap resamples.
    * Compute the linear regression slope for each of the bootstrapped datasets.
    * Compute the standard error of your bootstrapped slopes.
    * Compare the bootstrapped standard error with the standard slope standard error.

We write the below function to do the bootstrap simulation and calculation of slope coefficient for us
```{r q2-b}
# Input your answer here
set.seed(5003)
simple_regression_from_data <- function(df, B = 26) {
   coeffs <- c()
   for (i in 1:B) {
      dfnew <- q2.dat %>% dplyr::slice_sample(prop = 1, replace = T)
      coeffs[i] <- coef(lm(dfnew[,2]~ dfnew[,1], data = dfnew))[[2]]
   }
   return(coeffs)
}
coeffs <- simple_regression_from_data(q2.dat, B = 26)
data.frame(slope = coeffs) %>% ggplot(aes(x = slope)) + geom_boxplot() + geom_vline(colour = "maroon", size = 1, linetype = "dashed", xintercept = org_lin[[1]], show.legend = T) + theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) + ggtitle("Histogram of B = 26 bootstrap estimates of slope parameter from q2, w. original estimate")
```

We note that the standard deviation of the bootstrapped slope estimates is 
```{r}
sd(coeffs) #the bootstrap deviation calculated
org_lin[[2]] #the original standard error
```
Which are rather close.

### Question 3

A market research study into a new product for a company was conducted. Classification models to determine if a client will recommend their product is required based off their assessment of the company product. The table below shows describes the variables

| Variable        | Description                                                                                     | Variable type  |
| --------------- |:----------------------------------------------------------------------------------------------- |:-------------- |
| Will.recommend  | Whether the customer will recommend the product (Yes) or not (No)                               | Outcome        |
| Value           | The score from 1 (terrible) to 10 (great) about the value the customer sees in the product      | Feature        |
| Quality         | The score from 1 (terrible) to 10 (great) about the quality level of the product                | Feature        |
| Expertise       | The score from 1 (terrible) to 10 (great) about the expertise level of customer support staff   | Feature        |
| Communication   | The score from 1 (terrible) to 10 (great) about the communication level of the company          | Feature        |

Two classification models have been constructed, an LDA and an SVM. Using the fitted models `R` provided below. Determine which model performs better on the provided test data.

```{r q3-read-data}
lda.model <- readRDS('S2-2021-Q3-lda-model.rds')
svm.model <- readRDS('S2-2021-Q3-svm-model.rds')
test.data <- readRDS('S2-2021-Q3-test-data.rds')
```

a. **[4 marks]** Using the models, predict the labels on the test data. Then create (and print) a confusion matrix for each of the two models.

```{r q3-a}
# Input your answer here
library(e1071) #Remember to load in e1071!!!
levels(test.data$Will.recommend) #"Yes" is positive. 
pred_lda <- predict(lda.model, newdata = test.data)$class
pred_svm <- predict(svm.model, newdata = test.data)

caret::confusionMatrix(data = pred_lda, reference = test.data$Will.recommend, positive = "Yes") #LDA
caret::confusionMatrix(data = pred_svm, reference = test.data$Will.recommend, positive = "Yes") #SVM
```




b. **[2 marks]** Determine which is the better model on this set of test data using the confusion matrices or any other relevant classification metric discussed in the STAT5003 content.

We see from the confusion matrices that `svm.model` has a slightly higher accuracy ($91\%$ vs $89\%$) on the test data. The reasons for this however interesting, as `svm.model` has a sensitivity of $94\%$ vs. $96\%$ for lda, but for specificity we see svm with $78\%$ vs $57\%$ for lda. So depending on how much we believe in the generalisability of the extra accuracy, and care about specificity, we might choose `svm` as a more 'balanced' model. 

```{r q3-b}
# Input your answer here


```














