---
title: "Computer Test"
subtitle: "STAT5003 Semester 2, 2022"
date: "14th september, 2022"
author: "Victor 520540446 - TEST STUDENT"
header-includes:
   - \usepackage[utf8]{inputenc}
   - \usepackage{verbatim}
   - \usepackage[language]{babel}
   - \usepackage[encoding]{inputenc}
   - \usepackage{hyperref}
   - \usepackage{amsmath}
   - \usepackage{mathtools}
   - \usepackage{amssymb}
   - \usepackage{mathtools}
   - \usepackage{nicefrac}
   - \usepackage{fullpage}
   - \usepackage{stmaryrd}
   - \usepackage{aligned-overset}
   - \usepackage{pdfpages}
# Hvordan får  vi den til at printe February i stedet for februar??????
output: html_document
---

------------------------------------------------------------------------

```{=html}
<!-- RMD tips:
1. CTRL+SHIFT+C RMD-comments-out the selected lines, with in a standard HTML comment-out format. 

2. CTRL+ALT+I inserts a new r codechunck

3. Pressing CTRL+SHIFT+ENTER when over a code chunck gives you a preview of the results of the chunck

4. CTRL+SHIFT+K gives you a preview of the entire resulting HTML file.

5. Note the different results of '#HS 1' and 
'# HS 1' (without the '') in the output

6. It is possible to compile regular R-scripts into Rmd files - this is done by pressing CTRL+SHIFT+K while attending any R-script. <<<- Though this apparently doesn't work for HS Problems.R for some reason!?!?!? ->>>

7. Selective use of the echo=c(...) option within code chuncks allows assignment of a variable, to show the assignment in the knitted document, and showing the value of the assignment seamlessly as well - see HS2.3

8. It is possible to include results of R-analysis such as summary statistics in LaTeX-equations in RMD, see HS2.3

9. Adding fig.align="center" to a code chunk centers any figures generated by the chunck.

9.1 note that properties of codechunks seem casesensitive; fig.align="center" centers a figure, but fig.align="Center" (with capital C) doesn't

10. A new subtitle needs a blank line before itself: 
'works:

#### HS 7
'

'doesn't:
blablabla
#### HS 7
'

'doesn't either:
<!-- blablabla ->
#### HS 7
'
11. Pressing F7 when marking, or hovering over a word will spellcheck the word

12. CTRL + - (minus) zooms out, CTRL + + (plus) zooms in

13. CTRL + D Deletes the current line, or current selection of lines

14. THE FOLLOWING SOURCE EDITOR FOLDING METHODS:
14.1 Collapse current fold: ALT + L
14.1.1: Expand current fold: SHIFT + ALT + L
14.2 Collapse "all" subfolds: ALT + O <- !?!! Note that this leaves a small letter 'o' in the text !!?!
14.2.1 Expand "all" subfolds: SHIFT + ALT + O
14.3 Collapse all other folds: ALT + 0 (zero)

15. SHIFT + ALT + J allows you to jump to specific parts of the document

16. Writing a new line with '...' will cause all previous output to be hidden in the knittet document

17. Writing (q<-5) around R code, will both assign and print the code upon assignment 

18. Note that 'attach' only has the scope of the current R-chunck.

19. One way to get pdf printout is to compile a html-printout, and then, in-browser, 'print' the HTML page as a pdf.

20. CTRL + SHIFT + M gives the pipe operator.

21. Pressing CTRL + F3 searches on the selected word.

22. CTRL

23. ALT + SHIFT + DOWN copies a line to below.
-->
```
<!-- ---?--- How do I create a closeable Rmd section, such that I do not have to scroll through the LaTeX commands each time? - !!! Can be done with '-----' through this also creates a line in the knittet document. -->

<!-- How do I publish and share the HTML as a viewable (and linkable) website - this can be done through github? -->

<!-- How can I share R markdown files such that multiple people can edit them at the same time? -->

<!-- Do we need parindent controls as in LaTeX? -->

<!-- Use of the cache function to reduce recompile times -->

<!-- How to close current subsection with a keyboard shortcut? How to close subsubsections,...? - !!!See RMD tip 14!!! -->

<!-- Chunk naming? -->

<!-- How to define variables such that they have scope within their own ## segment? -->

<!-- How do I delete all non-needed variables for each new section in R??? -->

<!-- LaTeX commands -->

\newcommand{\C}{\mathbb{C}}

<!--- Komplekse tal --->

\newcommand{\R}{\mathbb{R}}

<!--- Reelle tal--->

\newcommand{\Q}{\mathbb{Q}}

<!---Rationelle tal--->

\newcommand{\Z}{\mathbb{Z}}

<!---Hele tal--->

\newcommand{\N}{\mathbb{N}}

<!---Naturlige tal--->

\newcommand{\E}{\mathbb{E}}

<!---mean--->

\newcommand{\F}{\mathbb{F}}

<!---Baggrundsrum sigma-alg--->

\newcommand{\B}{\mathbb{B}}

<!---Borel sigma--->

\newcommand{\K}{\mathbb{K}}

<!---Generel field--->

\newcommand{\RB}{\overline{\R}}

<!---Udvidede reelle tal--->

\newcommand{\ms}[1]{\mathscr{#1}}
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\BR}{\mathcal{B}\left(\R\right)}

<!---Borel på Reelle tal -->

\newcommand{\BRB}{\mathcal{B}\left(\RB\right))}

<!---Borel på udvidede reelle tal -->


\newcommand{\mf}[1]{\mathfrak{#1}} 
\newcommand{\mcG}[2]{\mathcal{#1}^1(#2)} 
\newcommand{\mcGG}[4]{\mathcal{#1}_{#3}^{#2}(#4)}
\newcommand{\GMR}{\left(X,\ms{A},\mu\right)}

<!---Generelt målrum -->

\newcommand{\PBS}{\lrp{\Omega,\F, P}}

<!--- Probability background space -->

\newcommand{\RMR}{\left(\R,\BR, \lambda\right)}

<!---Reelt målrum, m. Borel, og lebesgue mål. -->

<!---L_p spaces on [0,1] with m -->


\newcommand{\Lp}[1]{L_{#1}\lrp{\lrs{0,1},m}} 
\newcommand{\mclxy}{\mc{L}\lrp{X,Y}}
<!---Bounded linear functionals from X to Y -->

\newcommand{\mckxy}{\mc{K}\lrp{X,Y}}

<!---Compact Bounded linear functionals from X to Y -->

\newcommand{\mssr}{\ms{S}(\R)}

<!---The Schwartz space on $\R$ -->

<!---Arrows -->

\newcommand{\ra}{\rightarrow}

<!---Konvergens pil højre -->

\newcommand{\nra}{\nrightarrow}

<!---ikke Konvergens pil højre -->

\newcommand{\la}{\leftarrow}

<!---Konv pil venstre -->

\newcommand{\nla}{\nleftarrow}

<!---ikke Konvergens pil venstre -->

\newcommand{\lra}{\leftrightarrow}

<!---højre venstre pil -->

\newcommand{\nlra}{\nleftrightarrow}

<!---ikke højre venstre pil -->

\newcommand{\hra}{\hookrightarrow}

<!---Injektiv  pil højre -->

\newcommand{\Ra}{\Rightarrow}

<!---Implikations pil højre -->

\newcommand{\Lra}{\Leftrightarrow}

<!---Bi-implikations pil -->

\newcommand{\Uda}{\Updownarrow}

<!---Bi-implikations pil (op og ned) -->

\newcommand{\Da}{\Downarrow}

<!---implikations pil (ned) -->

\newcommand{\rhpu}{\rightharpoonup}

<!---Weak convergence in Hilbert spaces -->

<!-- LHS & RHS calculations -->

\newcommand{\swel}{\overset{\swarrow}{=}}

<!---Continue calculation on left hand side with equality -->

\newcommand{\sweq}{\overset{\swarrow}{\equiv}}

<!---Continue calculation on left hand side with equivalence -->

\newcommand{\seel}{\overset{\searrow}{=}}

<!---Continue calculation on right hand side with equality -->

\newcommand{\seeq}{\overset{\searrow}{\equiv}}

<!---Continue calculation on right hand side with equivalence -->

\newcommand{\inse}{\overset{\cdot}{=}}

<!--- Insert values in calculation -->

\newcommand{\eqd}{\overset{d.}{=}}

\newcommand{\PMX}{\mc{P}\left(X\right)}

<!---Potensmængde af X -->

\newcommand{\comp}{\mathsf{c}}

<!---Set compliment -->

\newcommand{\sm}{\setminus}

<!---mængdedifferens -->

<!--- Parenteser --->

\newcommand{\lrp}[1]{\mathopen{}\left({#1}\right)\mathclose{}}

<!-- \left("STUFF"\right) -->

\newcommand{\lrc}[1]{\mathopen{}\left\{{#1}\right\}\mathclose{}}

<!-- \left\{"STUFF"\right\} -->

\newcommand{\lrs}[1]{\mathopen{}\left[{#1}\right]\mathclose{}}

<!-- \left["STUFF"\right] -->

\newcommand{\lrb}[1]{\mathopen{}\left|{#1}\right|\mathclose{}}

<!-- \left|"STUFF"\right| -->

\newcommand{\inner}[2]{\mathopen{}\left\langle #1, #2 \right\rangle\mathclose{}}

<!-- <\left"STUFF1","STUFF2"\right> -->

\newcommand{\norm}[1]{\mathopen{}\left\lVert#1\right\rVert\mathclose{}}

<!-- \left||"STUFF"\right|| -->

\newcommand{\floor}[1]{\lfloor #1 \rfloor}

<!---Floor function --->

\newcommand{\ceil}[1]{\lceil #1 \rceil}

<!---ceil --->

\newcommand{\FFou}[1]{\mc{F}(#1)}

<!---Fourier Transform notation 1 --->

\newcommand{\Fou}[1]{\widehat{#1}}

<!---Fourier Transform notation 2 --->

<!--- Farver --->

\newcommand{\blue}[1]{\textcolor{blue}{{#1}}}

<!--- Turning text blue --->

\newcommand{\red}[1]{\textcolor{red}{{#1}}}

<!--- Turning text red --->

\newcommand{\green}[1]{\textcolor{green}{{#1}}}

<!--- Turning text green --->

\newcommand{\purple}[1]{\textcolor{purple}{{#1}}}

<!--- Turning text purple --->

\newcommand{\cyan}[1]{\textcolor{cyan}{{#1}}}

<!--- Turning text cyan --->

\newcommand{\orange}[1]{\textcolor{orange}{{#1}}}

<!--- Turning text orange --->

<!--- Oversetting bold accents --->


\newcommand{\boldhat}[1]{\mathbf{\hat{\text{$#1$}}}}
\newcommand{\boldbar}[1]{\mathbf{\bar{\text{$#1$}}}}
\newcommand{\boldtilde}[1]{\mathbf{\tilde{\text{$#1$}}}}
\newcommand{\boldcheck}[1]{\mathbf{\check{\text{$#1$}}}}
\newcommand{\indep}{\perp \!\!\! \perp}

<!---independence --->

\newcommand{\colvec}[1]{\begin{pmatrix}{#1}\end{pmatrix}}

<!-- Begin column vector - Doesn't seem to work with non-column vectors...-->

\newcommand{\nd}[2]{\mc{N}\lrp{{#1},{#2}}}

<!-- Normal distribution -->

\newcommand{\dnd}[2]{\sim\mc{N}\lrp{{#1},{#2}}}

<!-- Distributed as Normal distribution -->

\newcommand{\wnd}[3]{\frac{1}{\sqrt{2\pi\cdot {#3}}}e^{-\frac{1}{2}\frac{\lrp{{#1}-{#2}}^2}{{#3}}}}

<!-- With normal density (prob = #1, mean = #2, variance = #3 -->

\newcommand{\wpd}[2]{\frac{{#2}^{{#1}}\cdot e^{-{#2}}}{{#1}\!}}

<!-- With poisson density (prob = #1, mean = #2 -->

\newcommand{\ep}{\varepsilon}

<!-- \newcommand{\Rlogo}{![](R_logo.png){#id .class width=auto height=16px} } <!-- R logo implemented in text -->

<!-- Image insertion alla LaTeX doesn't seem to work too well..., but inserting the above gives the desired effect. -->

<!--???? \declareMathOperator{\SE}{SE} DOESN'T REALLY SEEM TO WORK????-->

<!-- #librar(reshape2) -->

<!-- #librar(lattice) -->

<!-- #librar(hebin) -->

<!-- #librar(xtable) -->

<!-- #librar(splines) -->

<!-- #librar(survival) -->

<!-- #librar(grid) -->

<!-- #librar(lpSolve) -->

<!-- #librar(unit) -->

<!-- #librar(MASS) #NOTE THAT MASS CAN CAUSE CONFLICTS WITH DPLYR OVER SELECT-FUNCTION -->




<!-- # !!!dplyr::select(indNoNA, where(is.numeric)) -->
<!-- indNoNA <- indians %>% drop_na() %>% mutate(across(c(pregnant:insulin,age), as.integer)) -->
<!-- install.packages("ggrepel") -->
<!-- !!! ```{r} -->
<!-- gdf <- -->
<!--   tibble(g = c(1, 1, 2, 3), v1 = 10:13, v2 = 20:23) %>% -->
<!--   group_by(g) -->
<!-- gdf -->

<!-- set.seed(1) -->

<!-- # Outside: 1 normal variate -->
<!-- n <- rnorm(1) -->
<!-- n -->
<!-- gdf %>% mutate(across(v1:v2, ~ .x + n)) -->
<!-- ``` -->

<!-- !!! ```{r} -->
<!-- ? family -->
<!-- ``` -->

<!-- !!! # ```{r} -->
<!-- # ifelse -->
<!-- # ``` -->

<!-- # ```{r} -->
<!-- # df <- df %>% -->
<!-- #   mutate(n = row_number()) %>% #create row number if you dont have one -->
<!-- #   select(n, everything()) # put 'n' at the front of the dataset -->
<!-- # train <- df %>% -->
<!-- #   group_by(var1, var2) %>% #any number of variables you wish to partition by proportionally -->
<!-- #   sample_frac(.7) # '.7' is the proportion of the original df you wish to sample -->
<!-- # test <- anti_join(df, train) # creates test dataframe with those observations not in 'train.' -->
<!-- # ``` -->


<!-- ```{r} -->
<!-- RColorBrewer::brewer.pal(10, "Set1") #but then try with 9 -->
<!-- ``` -->

<!-- #!!! NOTE THAT sample does not work well together with dataframes!!!! -->


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(fig.align = 'center')
Sys.setenv("TZ" = "Australia/Sydney")
library(tidyverse)
library(gridExtra)
theme_set(theme_minimal())
library(MASS) #Has a conflict with dplyr regarding select.
library(reshape2)
library(caret) #Used for Machine Learning
#library(plot.matrix) 
library(Matrix)
library(expm)
#library(plotly) #for 3D plotting
#library(reticulate) #Used for saving plotly images
#library(nloptr) #optimisation
#library(lpSolve) #linear programming
library(microbenchmark)
library(scales) #used for log trans of ggplot
#library(stats4) #mle and stuff
#set.seed(314)
library(mlbench)
library(e1071)

varnametotext <- function(v){
   deparse(substitute(v))
}
Stdresplot <- function(model, main = paste("(Estimate, Std. Res.)-plot of", deparse(substitute(model))), ylab ="Standardized residuals", ...) {
 fit <- fitted(model)
 rst <- rstandard(model)
 qplot(fit, rst, main = main, ylab = ylab, ylim = c(-max(3.2,max(abs(rst))), max(3.2,max(abs(rst)))) )+geom_hline(yintercept = 0) #Largest symmetric interval (around 0) of (-3.2,3.2) or (-largest absolute rst, largest absolute rst)
}
QQplotdraw <- function(model, main = paste("Normal QQ-plot of", deparse(substitute(model))), xlab = "Theoretical Quantiles", ylab ="Sample Quantiles", ...) {
   rst <- rstandard(model)
   #dataname <- getCall(lm_LT)$data
   ggplot(data = eval(getCall(model)$data), main = main, xlab = xlab, ylab = ylab) + geom_qq() + geom_qq_line() + aes(sample = rst)
} #main, xlab, ylab call do not work for some reason
StdresQQPlot <- function(model,...) {
   p1 <- Stdresplot(model,...)
   p2 <- QQplotdraw(model,...)
   #library(gridExtra)
   grid.arrange(p1,p2, ncol = 2)
}
```


This document was compiled on: `r format(Sys.time(), "%a %b %d  %X %Y %Z")`

### Instructions

1. This is an open book quiz, and you are allowed to search the Internet and the course webpage to access any descriptions and `R` code that may help you to solve the questions. However, be mindful that searching for the solution may take longer than you may be capable of doing by youself. Keep track of your time regularly.
2. Place your answers in the code chunk spaces provided adding typed comments below the code chunks as necessary if required (some questions may ask you to interpret your output).
3. We suggest you begin by **knitting** (compiling) the Rmd to make sure the template works on your system.
4. It's a good idea to submit your work **regularly** - if you end up submitting the final version late, the marker can go back and mark only the on-time submission.
5. It is suggested to set an alarm to at least 5-10 mins before the deadline to be able to compile and submit the HTML file on canvas.
6. Two marks will be awarded if a complete HTML file with compiled R code is submitted.
7. No additional packages are required for this test but you are free to use `tidyverse` functions if you wish.


### Question 1

A dataset involving a text encoding of various text documents using Natural Language Processing (NLP) has been given in the files `S2-2022-q1-list.rds` and `S2-2022-q1-df.rds`. There are 10 numeric variables and a categorical variable describing the Genre of the text in the `Genre` variable (coded as `f` for "Fantasy", `a` for "Adventure" and `c` for Crime) along with the model complexity in the `Model` variable. More details are given in this summary table

| R variable(s) | Description                                                                                    |
|:--------------|:-----------------------------------------------------------------------------------------------|
| `X1` -- `X10` | Ten numeric variables encoding a written text                                                  |
| `Genre`       | Genre of the text document coded as `c` for "Crime", `a` for "Adventure" and `f` for "Fantasy" |
| `Model`       | Type of model, coded as either `Basic` or `State.of.the.art`                                   |


Consider the following questions below.

a. __[3 marks]__ Verify that both the data sets, `q1.df` and `q1.list`, are both lists in `R` **and** have similar structure. Comment on how the structure is different.

We use the command `typeof` to check the type of object. We may use `str` to check the structure.
```{r q1a}
q1.list <- readRDS("S2-2022-q1-list.rds")
q1.df <- readRDS("S2-2022-q1-df.rds")
# Enter your answer here
typeof(q1.list)
typeof(q1.df)

str(q1.list)
str(q1.df)
```
The structure is similar, you have an extra `class` label of `dataframe in df`.

b. __[3 marks]__ Using the `attributes` function in `R` (see `? attributes`), print the attributes for `q1.list` and `q1.df`. `q1.list` should only have a `names` attribute which contains a character vector of the variable names. Show `q1.df` has the same attributes as `q1.list` and also contains two more attributes. Comment on the details of the two extra attributes.
```{r q1b}
# Enter your answer here
q1.list %>% attributes()
q1.df %>% attributes()
```
We see that the `$names` attribute is shared amongst `list` and `df`, but `df` also contains a rownames and `class` attribute.


c. __[2 marks]__ Convert `q1.list` to a `data.frame` by using `as.data.frame` and assign it the variable name `q1.list.to.df` and show it is identical to `q1.df` using `identical`.
```{r q1c}
# Enter your answer here
q1.list.to.df <- as.data.frame(q1.list) # Edit this line
identical(q1.list.to.df, q1.df) # This should evaluate to TRUE
```

d. __[3 marks]__ Convert `q1.list` to a `data.frame` by changing its attributes by using the `attr` function (see `? attr`). In the first approach use `as.data.frame` and assign it the variable name `q1.list.to.df` and show it is identical to `q1.df` using `identical`.
```{r q1d}
# Enter your answer here
#attr(q1.list, "class") <- "data.frame"
q1.to.df.via.attr <- base::attr(q1.list, "data.frame") # Edit this line and add code below to modify attributes
#attr(q1.to.df.via.attr, "class") <- "as.data.frame"
identical(q1.to.df.via.attr, q1.df) # This should evaluate to TRUE

setNames(as.data.frame(q1.list$row.names), attr(q1.list$row.names, "names"))
```
Didn't get this working.

e. __[3 marks]__ Produce a comparative boxplot of the `X5` variable split by `Genre`.
```{r q1e}
# Enter your answer here
q1.df %>% ggplot(mapping = aes(x = X5, colour = Genre)) + geom_boxplot() #+ #scale_colour_discrete(colour=c('Fantasy', 'Adventure', 'Crime'))
```

We may produce the boxplot using `ggplot`.

f. __[2 marks]__ Compute the mean values for the first three numeric variables (`X1`, `X2` and `X3`) when the `Genre` is `Crime` and the `Model` is `State.of.the.art`.

We may calculate the requested with the following command.
```{r q1f}
   q1.df %>% dplyr::filter(Genre == 'c', Model == 'State.of.the.Art') %>% dplyr::select(X1, X2, X3) %>% colMeans()
```

g. __[4 marks]__ The data is hard to visualize with 10 variables. Conduct a Principal Components Analysis (PCA) using `prcomp` with the data centered and scaled. Then produce a scatterplot of the first two principal components and colour the points by their `type`. Using the visualiaztion, **comment** if the PCA can help explain the document type.

Note that the question is ambiguous as there is three ways to construe `type` as we have no such variable available. We thus go for a 'colour and shape' visualisation to visualise type for the first two principal components.
```{r q1g}
q1.df_num <- q1.df %>% dplyr::select(-c("Genre", "Model"))
q1_pca <- prcomp(q1.df_num, scale = T, center = T)

q1_pca_wlabel <- data.frame(q1_pca$x, Genre = q1.df$Genre, Model = q1.df$Model)
#head(q1_pca_wlabel)[,1:6]
q1_pcVarEx <- as.numeric(q1_pca$sdev^2)[1:2]/sum(as.numeric(q1_pca$sdev^2))

##
(q1_pca_p <- ggplot(q1_pca_wlabel, 
       aes(x = PC1, y = PC2, colour = as.factor(q1_pca_wlabel$Genre), shape = as.factor(q1_pca_wlabel$Model))) +
   geom_point(size = 2, alpha = 0.8) +  labs(colour = 'Genre', shape = "Model", 
                               x = paste0("PC1 (", signif(q1_pcVarEx[1],3)*100, "%)"),
                               y = paste0("PC2 (", signif(q1_pcVarEx[2],3)*100, "%)"),
                               title = paste0("PCA plot of NLP")))
###
```

It seems that one might fairly easily be able to seperate the genres of data based on the two first principal components, though it seems harder to seperate the model type based on the first two components.


### Question 2

The standard multiple regression model with three features assumes that the response and features follow the model
\[
  Y_i = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \beta_3 X_3  +\varepsilon \qquad \varepsilon \sim \mathcal N(0, \sigma^2).
\]
This can lead to the likelihood model (you do not need to show this) where the log likelihood of the parameters
$\boldsymbol{\theta} = \left( \beta_0, \beta_1, \beta_2, \beta_3, \sigma\right)$ is given by
\[
  \mathcal L(\boldsymbol{\theta}|\mathcal X) = \begin{cases} -\infty, & \qquad \text{if } \sigma < 0;\\
  -\frac{n}{2}\log(2 \pi) - n\log (\sigma) - \frac{1}{2\sigma^2} \sum_{i = 1}^n (Y_i - \beta_0 - \beta_1 X_{1i} - \beta_2X_{2i} - \beta_3 X_{3i})^2, & \qquad \text{otherwise}.\end{cases}
\]
where $\mathcal X = (Y_1, \ldots, Y_n, X_{11}, \ldots, X_{1n}, X_{21}, \ldots, X_{2n}, X_{31}, \ldots, X_{3n})$

For this question consider estimating a linear model using both the standard least squares fitting procedure using `lm` and an approach using the method of Maximum Likelihood Estimation (MLE). In particular, consider the `property.dat` data available in `readRDS` command below. A description of the data is given in the table below

| R variable       | Variable | Description                                        |
|:-----------------|:---------|:---------------------------------------------------|
| `Sold.price`     | $Y$      |   Last sold price (in $AUD)                        |
| `land.estimate`  | $X_1$    |   Estimated land value (in $AUD)                   |
| `existing`       | $X_2$    |   Estimated value of existing structure (in $AUD)  |
| `area`           | $X_3$    |   Size of property (in square metres)              |


a. __[3 marks]__ Inspect the `property.dat` data, determining the dimension of the data and produce a matrix scatterplot (using the function `pairs` or other equivalent function).
```{r q2a, message=FALSE}
property.dat <- readRDS("S2-2022-q2.rds")
property.dat %>% head()
property.dat %>% dim()
library(GGally)
property.dat %>% ggpairs()
# Enter your answer here
```

b. __[2 marks]__ Fit the linear regression using the `lm` function in `R` and extract the regression coefficients (the $\beta$ values) and the estimate of $\sigma$.
```{r q2b}
# Enter your answer here
lin_mod <- lm(Sold.price ~ ., data = property.dat)

#We can attain the estimates using summary
summary(lin_mod)

#In particular the betas:
(betas <- summary(lin_mod)$coef[1:4,1])

#and sigma:
(sigma <- summary(lin_mod)$sigma)
```

c. __[3 marks]__ Define a function in `R` that computes the _negative_ log-likelihood as a function of $\boldsymbol{\theta}$ defined above. (Note $\boldsymbol{\theta} = (\beta_0, \beta_1, \beta_2, \beta_3, \sigma)$ has 5 elements and will require a function with five input arguments e.g. `fun <- function(v, w, x, y, z)` has five arguments `v, w, x, y, z`)
```{r q2c}
# Enter your answer here
# Edit this to be an appropriate function and not NULL

LLH <- function(x, beta0, beta1, beta2, beta3, sigma) {
   n <- nrow(x)
   if (sigma >=0) {
      return(-n/2*log(2*pi)-n*log(sigma)-1/(2*sigma^2)*sum((x$Sold.price - beta0 - beta1*x$land.estimate-beta2*x$existing-beta3*x$area)^2))
   }
   else {
      return(-Inf)
   }
}
minus_LLH <- function(beta0, beta1, beta2, beta3, sigma) {
 return(-LLH(x = property.dat, beta0, beta1, beta2, beta3, sigma))  
}
```

d. __[2 marks]__ As an alternative algorithm to estimate the regression coefficients and $\sigma$, use the `property.dat` data to compute the MLE of $\boldsymbol{\theta}$ using the using the `stats4::mle` function (i.e. the function `mle` in the `stats4` package). **Print** the mle estimates in the output belowe. __Hint__: Start the algorithm with the values $\beta_i = 0$ and $\sigma = 1$ by using the `start` argument in `stats4::mle` or setting default arguments in the `negLogLikelihood` function above.
```{r q2d}
# Enter your answer here
library(stats4)
mle_est <- stats4::mle(minus_LLH, start = list(beta0 = 0, beta1 = 0, beta2 = 0, beta3 = 0, sigma = 1))
mle_est
(mlecoef <- coef(mle_est))
```

e. __[2 marks]__ Compare the outputs generated from `lm` and the MLE method above and **comment**. To do this, take the code below that produces a matrix with missing values and replace the missing values with the appropriate estimated coefficients from each model.
```{r q2e}
# Enter your answer here and edit some of the lines or add lines below as appropriate
as.numeric(betas)

coef.table <- matrix(cbind(c(as.numeric(betas), as.numeric(sigma)), as.numeric(mlecoef)), nrow = 5, ncol = 2,
                     dimnames = list(c(paste0("beta", 0:3), "sigma"), c("Least squares", "MLE")))
coef.table
```

We see that LS has signifigantly higher beta0 and sigma than mle, while the other quantaties are somewhat more comparable.

f. __[3 marks]__ Compute the predicted `Sold.prices` using the least squares model (from the model generated by `lm`) and using the MLE estimate computed earlier. Print the first six predictions from each model by using the `head` function.
```{r q2f}
ls_pred <- predict(lin_mod)
mle_pred <- mlecoef[1] + mlecoef[2]*property.dat$land.estimate + mlecoef[3]*property.dat$existing + mlecoef[4]*property.dat$area

head(ls_pred)
head(mle_pred)
```
Seems similar predictive performace.

g. __[3 marks]__ Using the predicted values in part f. above, compute the Root Mean Square Error (RMSE) of both models.
$$
    RMSE = \sqrt{\frac{\sum_{i = 1}^n (Y_i - \widehat{Y}_i)^2}{n}}
$$
where $Y_i$ is the observed sold price and $\widehat Y_i$ is the predicted sold price from the model.
```{r q2g}
# Enter your answer here
RMSE_func <- function(true, pred) {
   n <- length(true)
   return(sqrt((sum((true-pred)^2))/(n)))
}

c(`RMSE:Least Squares` = RMSE_func(true = as.numeric(property.dat$Sold.price), pred = as.numeric(ls_pred)), `RMSE: MLE` = RMSE_func(true = as.numeric(property.dat$Sold.price), as.numeric(mle_pred))) # Replace the NA values with the RMSE for each model
```
We see that Least Squares has lowest RMSE.

































