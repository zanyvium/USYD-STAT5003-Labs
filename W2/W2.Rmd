---
title: "W2 STAT5003 RMD"
author: "Victor Z. Nygaard, vnyg7406"
header-includes:
   - \usepackage[utf8]{inputenc}
   - \usepackage{verbatim}
   - \usepackage[language]{babel}
   - \usepackage[encoding]{inputenc}
   - \usepackage{hyperref}
   - \usepackage{amsmath}
   - \usepackage{mathtools}
   - \usepackage{amssymb}
   - \usepackage{mathtools}
   - \usepackage{nicefrac}
   - \usepackage{fullpage}
   - \usepackage{stmaryrd}
   - \usepackage{aligned-overset}
   - \usepackage{pdfpages}
date: "Last compiled on `r format(Sys.time(), '%d. %B, %Y')`"
# Hvordan får  vi den til at printe February i stedet for februar??????
output: html_document
---

------------------------------------------------------------------------

```{=html}
<!-- RMD tips:
1. CTRL+SHIFT+C RMD-comments-out the selected lines, with in a standard HTML comment-out format. 

2. CTRL+ALT+I inserts a new r codechunck

3. Pressing CTRL+SHIFT+ENTER when over a code chunck gives you a preview of the results of the chunck

4. CTRL+SHIFT+K gives you a preview of the entire resulting HTML file.

5. Note the different results of '#HS 1' and 
'# HS 1' (without the '') in the output

6. It is possible to compile regular R-scripts into Rmd files - this is done by pressing CTRL+SHIFT+K while attending any R-script. <<<- Though this apparently doesn't work for HS Problems.R for some reason!?!?!? ->>>

7. Selective use of the echo=c(...) option within code chuncks allows assignment of a variable, to show the assignment in the knitted document, and showing the value of the assignment seamlessly as well - see HS2.3

8. It is possible to include results of R-analysis such as summary statistics in LaTeX-equations in RMD, see HS2.3

9. Adding fig.align="center" to a code chunk centers any figures generated by the chunck.

9.1 note that properties of codechunks seem casesensitive; fig.align="center" centers a figure, but fig.align="Center" (with capital C) doesn't

10. A new subtitle needs a blank line before itself: 
'works:

#### HS 7
'

'doesn't:
blablabla
#### HS 7
'

'doesn't either:
<!-- blablabla ->
#### HS 7
'
11. Pressing F7 when marking, or hovering over a word will spellcheck the word

12. CTRL + - (minus) zooms out, CTRL + + (plus) zooms in

13. CTRL + D Deletes the current line, or current selection of lines

14. THE FOLLOWING SOURCE EDITOR FOLDING METHODS:
14.1 Collapse current fold: ALT + L
14.1.1: Expand current fold: SHIFT + ALT + L
14.2 Collapse "all" subfolds: ALT + O <- !?!! Note that this leaves a small letter 'o' in the text !!?!
14.2.1 Expand "all" subfolds: SHIFT + ALT + O
14.3 Collapse all other folds: ALT + 0 (zero)

15. SHIFT + ALT + J allows you to jump to specific parts of the document

16. Writing a new line with '...' will cause all previous output to be hidden in the knittet document

17. Writing (q<-5) around R code, will both assign and print the code upon assignment 

18. Note that 'attach' only has the scope of the current R-chunck.

19. One way to get pdf printout is to compile a html-printout, and then, in-browser, 'print' the HTML page as a pdf.

20. CTRL + SHIFT + M gives the pipe operator.

21. Pressing CTRL + F3 searches on the selected word.

22. CTRL
-->
```
<!-- ---?--- How do I create a closeable Rmd section, such that I do not have to scroll through the LaTeX commands each time? - !!! Can be done with '-----' through this also creates a line in the knittet document. -->

<!-- How do I publish and share the HTML as a viewable (and linkable) website - this can be done through github? -->

<!-- How can I share R markdown files such that multiple people can edit them at the same time? -->

<!-- Do we need parindent controls as in LaTeX? -->

<!-- Use of the cache function to reduce recompile times -->

<!-- How to close current subsection with a keyboard shortcut? How to close subsubsections,...? - !!!See RMD tip 14!!! -->

<!-- Chunk naming? -->

<!-- How to define variables such that they have scope within their own ## segment? -->

<!-- How do I delete all non-needed variables for each new section in R??? -->

<!-- LaTeX commands -->

\newcommand{\C}{\mathbb{C}}

<!--- Komplekse tal --->

\newcommand{\R}{\mathbb{R}}

<!--- Reelle tal--->

\newcommand{\Q}{\mathbb{Q}}

<!---Rationelle tal--->

\newcommand{\Z}{\mathbb{Z}}

<!---Hele tal--->

\newcommand{\N}{\mathbb{N}}

<!---Naturlige tal--->

\newcommand{\E}{\mathbb{E}}

<!---mean--->

\newcommand{\F}{\mathbb{F}}

<!---Baggrundsrum sigma-alg--->

\newcommand{\B}{\mathbb{B}}

<!---Borel sigma--->

\newcommand{\K}{\mathbb{K}}

<!---Generel field--->

\newcommand{\RB}{\overline{\R}}

<!---Udvidede reelle tal--->

\newcommand{\ms}[1]{\mathscr{#1}}
\newcommand{\mc}[1]{\mathcal{#1}}
\newcommand{\BR}{\mathcal{B}\left(\R\right)}

<!---Borel på Reelle tal -->

\newcommand{\BRB}{\mathcal{B}\left(\RB\right))}

<!---Borel på udvidede reelle tal -->

\newcommand{\mf}[1]{\mathfrak{#1}} 
\newcommand{\mcG}[2]{\mathcal{#1}^1(#2)} 
\newcommand{\mcGG}[4]{\mathcal{#1}_{#3}^{#2}(#4)}
\newcommand{\GMR}{\left(X,\ms{A},\mu\right)}

<!---Generelt målrum -->

\newcommand{\PBS}{\lrp{\Omega,\F, P}}

<!--- Probability background space -->

\newcommand{\RMR}{\left(\R,\BR, \lambda\right)}

<!---Reelt målrum, m. Borel, og lebesgue mål. -->

\newcommand{\MRBPBR}{\mc{M}_{\RB}^+\left(\BR\right)}

<!---Mængden af positive målelige funktioner som sender (R,BR) over i (RB, BRB) -->

\newcommand{\MRPBR}{\mc{M}_{\R}^+\left(\BR\right)}

<!---Mængden af positive målelige funktioner som sender (R,BR) over i (R, BR) -->

<!---L_p spaces on [0,1] with m -->

\newcommand{\Lp}[1]{L_{#1}\lrp{\lrs{0,1},m}} 
\newcommand{\mclxy}{\mc{L}\lrp{X,Y}}

<!---Bounded linear functionals from X to Y -->

\newcommand{\mckxy}{\mc{K}\lrp{X,Y}}

<!---Compact Bounded linear functionals from X to Y -->

\newcommand{\mssr}{\ms{S}(\R)}

<!---The Schwartz space on $\R$ -->

<!---Arrows -->

\newcommand{\ra}{\rightarrow}

<!---Konvergens pil højre -->

\newcommand{\nra}{\nrightarrow}

<!---ikke Konvergens pil højre -->

\newcommand{\la}{\leftarrow}

<!---Konv pil venstre -->

\newcommand{\nla}{\nleftarrow}

<!---ikke Konvergens pil venstre -->

\newcommand{\lra}{\leftrightarrow}

<!---højre venstre pil -->

\newcommand{\nlra}{\nleftrightarrow}

<!---ikke højre venstre pil -->

\newcommand{\hra}{\hookrightarrow}

<!---Injektiv  pil højre -->

\newcommand{\Ra}{\Rightarrow}

<!---Implikations pil højre -->

\newcommand{\Lra}{\Leftrightarrow}

<!---Bi-implikations pil -->

\newcommand{\Uda}{\Updownarrow}

<!---Bi-implikations pil (op og ned) -->

\newcommand{\Da}{\Downarrow}

<!---implikations pil (ned) -->

\newcommand{\rhpu}{\rightharpoonup}

<!---Weak convergence in Hilbert spaces -->

<!-- LHS & RHS calculations -->

\newcommand{\swel}{\overset{\swarrow}{=}}

<!---Continue calculation on left hand side with equality -->

\newcommand{\sweq}{\overset{\swarrow}{\equiv}}

<!---Continue calculation on left hand side with equivalence -->

\newcommand{\seel}{\overset{\searrow}{=}}

<!---Continue calculation on right hand side with equality -->

\newcommand{\seeq}{\overset{\searrow}{\equiv}}

<!---Continue calculation on right hand side with equivalence -->

\newcommand{\inse}{\overset{\cdot}{=}}

<!--- Insert values in calculation -->

\newcommand{\eqd}{\overset{d.}{=}}

\newcommand{\PMX}{\mc{P}\left(X\right)}

<!---Potensmængde af X -->

\newcommand{\comp}{\mathsf{c}}

<!---Set compliment -->

\newcommand{\sm}{\setminus}

<!---mængdedifferens -->

<!--- Parenteser --->

\newcommand{\lrp}[1]{\mathopen{}\left({#1}\right)\mathclose{}}

<!-- \left("STUFF"\right) -->

\newcommand{\lrc}[1]{\mathopen{}\left\{{#1}\right\}\mathclose{}}

<!-- \left\{"STUFF"\right\} -->

\newcommand{\lrs}[1]{\mathopen{}\left[{#1}\right]\mathclose{}}

<!-- \left["STUFF"\right] -->

\newcommand{\lrb}[1]{\mathopen{}\left|{#1}\right|\mathclose{}}

<!-- \left|"STUFF"\right| -->

\newcommand{\inner}[2]{\mathopen{}\left\langle #1, #2 \right\rangle\mathclose{}}

<!-- <\left"STUFF1","STUFF2"\right> -->

\newcommand{\norm}[1]{\mathopen{}\left\lVert#1\right\rVert\mathclose{}}

<!-- \left||"STUFF"\right|| -->

\newcommand{\floor}[1]{\lfloor #1 \rfloor}

<!---Floor function --->

\newcommand{\ceil}[1]{\lceil #1 \rceil}

<!---ceil --->

\newcommand{\FFou}[1]{\mc{F}(#1)}

<!---Fourier Transform notation 1 --->

\newcommand{\Fou}[1]{\widehat{#1}}

<!---Fourier Transform notation 2 --->

<!--- Farver --->

\newcommand{\blue}[1]{\textcolor{blue}{{#1}}}

<!--- Turning text blue --->

\newcommand{\red}[1]{\textcolor{red}{{#1}}}

<!--- Turning text red --->

\newcommand{\green}[1]{\textcolor{green}{{#1}}}

<!--- Turning text green --->

\newcommand{\purple}[1]{\textcolor{purple}{{#1}}}

<!--- Turning text purple --->

\newcommand{\cyan}[1]{\textcolor{cyan}{{#1}}}

<!--- Turning text cyan --->

\newcommand{\orange}[1]{\textcolor{orange}{{#1}}}

<!--- Turning text orange --->

<!--- Oversetting bold accents --->


\newcommand{\boldhat}[1]{\mathbf{\hat{\text{$#1$}}}}
\newcommand{\boldbar}[1]{\mathbf{\bar{\text{$#1$}}}}
\newcommand{\boldtilde}[1]{\mathbf{\tilde{\text{$#1$}}}}
\newcommand{\boldcheck}[1]{\mathbf{\check{\text{$#1$}}}}

\newcommand{\indep}{\perp \!\!\! \perp}

<!---independence --->

\newcommand{\colvec}[1]{\begin{pmatrix}{#1}\end{pmatrix}}

<!-- Begin column vector - Doesn't seem to work with non-column vectors...-->

\newcommand{\nd}[2]{\mc{N}\lrp{{#1},{#2}}}

<!-- Normal distribution -->

\newcommand{\dnd}[2]{\sim\mc{N}\lrp{{#1},{#2}}}

<!-- Distributed as Normal distribution -->

\newcommand{\wnd}[3]{\frac{1}{\sqrt{2\pi\cdot {#3}}}e^{-\frac{1}{2}\frac{\lrp{{#1}-{#2}}^2}{{#3}}}}

<!-- With normal density (prob = #1, mean = #2, variance = #3 -->

\newcommand{\wpd}[2]{\frac{{#2}^{{#1}}\cdot e^{-{#2}}}{{#1}\!}}

<!-- With poisson density (prob = #1, mean = #2 -->

\newcommand{\ep}{\varepsilon}

<!-- \newcommand{\Rlogo}{![](R_logo.png){#id .class width=auto height=16px} } <!-- R logo implemented in text -->

<!-- Image insertion alla LaTeX doesn't seem to work too well..., but inserting the above gives the desired effect. -->

<!--???? \declareMathOperator{\SE}{SE} DOESN'T REALLY SEEM TO WORK????-->

<!-- #librar(reshape2) -->

<!-- #librar(lattice) -->

<!-- #librar(hebin) -->

<!-- #librar(xtable) -->

<!-- #librar(splines) -->

<!-- #librar(survival) -->

<!-- #librar(grid) -->

<!-- #librar(lpSolve) -->

<!-- #librar(unit) -->

<!-- #librar(MASS) #NOTE THAT MASS CAN CAUSE CONFLICTS WITH DPLYR OVER SELECT-FUNCTION -->

<!-- #THOUGHTS: -->
<!-- #4. Can you change the sparse matrix simulator to for example, instead of picking a position & effect combo,  -->
<!-- # and seeing if this works, pick a position, and then try up to 100 different effects, to see if any of these work, -->
<!-- # and then move on to a new position after having tried the 100 different effects? -->
<!-- #5. Could you do a pivot-point determinant calculation based checking of positive definiteness, -->
<!-- # where we start by simulating, for example a fifth of the required support, from the "upper" fifth of the matrix -->
<!-- #6. Could Sparse Matrixes be generated in RCpp? -->
<!-- #7. nlm package. -->
<!-- #8. slim package for Dantzig estimator. -->
<!-- #9. Implement alpha and X0 in MultidimOU. -->
<!-- #10 Size of matrix dependent convergence (dividing by ||A||) -->
<!-- # SHIFT + ALT + DownArrow Copies above line. -->
<!-- #Crossvalidation for choice of lambda: Lowest difference/squared difference -->
<!-- #between training data estimate and Lasso estimate (???) vs. some sort of -->
<!-- #support recovery criteria, or some mix of difference and support recovery.   -->
<!-- #Get MatrixHeatMap to start rowcount at 1, and not 0. -->
<!-- #11. Standardisation for Lasso matrix -->
<!-- #12. LARS for Lasso. -->
<!-- #13. Row and column Sparsity for Sparse matrix generation. -->
<!-- #14. Code commenting. -->
<!-- #15. Rmd. -->
<!-- #16.Plot2D universality -->
<!-- #17.Plot3D Better colours, Bar could be smaller, default zoom and angle, bar should say "time". -->
<!-- #18. Log-transforms for stability? -->
<!-- #Picture compile and save R-document/routine. <- implemented as part of RMD? <- would be ideal. -->
<!-- #One could perhaps optimise the optim functions using apply. -->
<!-- Fix save of 3dplot -->
<!-- nloptr does not do convex methods, is Dantzig convex? -->
<!-- Dantzig via linear programming for convex optimisation with constraints. - see fastlp documentation -->
<!-- For better breaks see https://stackoverflow.com/questions/15622001/how-to-display-only-integer-values-on-an-axis-using-ggplot2 -->
<!-- MatrixHeatMap limits = min and max, or symmetric instead? -->
<!-- Check for positive mindiag argument to SparseMat? -->
<!-- Offdiagonal size options for SparseMat? -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(fig.align = 'center')
library(tidyverse)
library(gridExtra)
theme_set(theme_minimal())
library(MASS) #Has a conflict with dplyr regarding select.
library(reshape2)
library(plot.matrix)
library(Matrix)
library(expm)
library(plotly) #for 3D plotting
library(reticulate) #Used for saving plotly images
library(nloptr)
library(lpSolve)
library(microbenchmark)
library(scales) #used for log trans of ggplot
set.seed(314)

varnametotext <- function(v){
   deparse(substitute(v))
}
Stdresplot <- function(model, main = paste("(Estimate, Std. Res.)-plot of", deparse(substitute(model))), ylab ="Standardized residuals", ...) {
 fit <- fitted(model)
 rst <- rstandard(model)
 qplot(fit, rst, main = main, ylab = ylab, ylim = c(-max(3.2,max(abs(rst))), max(3.2,max(abs(rst)))) )+geom_hline(yintercept = 0) #Largest symmetric interval (around 0) of (-3.2,3.2) or (-largest absolute rst, largest absolute rst)
}
QQplotdraw <- function(model, main = paste("Normal QQ-plot of", deparse(substitute(model))), xlab = "Theoretical Quantiles", ylab ="Sample Quantiles", ...) {
   rst <- rstandard(model)
   #dataname <- getCall(lm_LT)$data
   ggplot(data = eval(getCall(model)$data), main = main, xlab = xlab, ylab = ylab) + geom_qq() + geom_qq_line() + aes(sample = rst)
} #main, xlab, ylab call do not work for some reason
StdresQQPlot <- function(model,...) {
   p1 <- Stdresplot(model,...)
   p2 <- QQplotdraw(model,...)
   #library(gridExtra)
   grid.arrange(p1,p2, ncol = 2)
}
```



We load in the data:
```{r}
data <- read.csv('../Data/Melbourne_housing_FULL.csv', stringsAsFactors = T)
head(data)
```

We subset the data:
```{r}
#subset(Suburb == "Brunswick" | "Suburb" == "Craigieburn" | "Suburb" == "Hawthorn"))
nrow(data)
subSuburb <- data %>% subset(Suburb == c("Brunswick", "Craigieburn", "Hawthorn"))
unique(subSuburb$Suburb)
head(subSuburb)
```


We may also use the `summary` function to summarise basic statistics of the data:
```{r}
summary(subSuburb)
```

We note the presence of missing data: 
```{r}
#as.numeric(apply(subSuburb,1,anyNA))
sum(apply(subSuburb,1,anyNA)) #how many rows contain a NA?
#269/375 rows contain NA's.
# One should consider doing imputation methods.
#
#We check where the NA's lie.
colSums(is.na(subSuburb)) # #missing values for each feature
#ggplot() + geom_bar(aes(x=as.numeric(rowSums(is.na(subSuburb)))),width = 1) # #missing values for each datapoint
#
#subSuburb[is.na(subSuburb$Price),]
```
As imputation methods are outside the course scope of this course, we choose to ignore the missing values.
Under this fallacy, we may calculate the mean of each of the suburbs using `tapply`
```{r}
tapply(subSuburb$Price, subSuburb$Suburb, mean, na.rm = T)[c("Brunswick", "Craigieburn", "Hawthorn")]
```
We might plot the non-missing house prices for each suburb.
```{r, message = FALSE, warning = FALSE}
subSuburb %>% ggplot(aes(Price)) + geom_histogram() + facet_wrap(~Suburb,ncol = 3)
```

We start by building a simple linear regression model, though noting once again that there are a significant amount of missing data (with a total of 246 data points deleted due to missing values):
```{r}
PriceBuildArea_lm <- lm(Price ~ BuildingArea, data = subSuburb)
summary(PriceBuildArea_lm)
Stdresplot(PriceBuildArea_lm)
plot(PriceBuildArea_lm)
```
We read off that according to the model, and under the model assumptions, `BuildingArea` is highly significant, while an intercept is not. We may however call into doubt the model-assumptions that underline the Gaussian linear model.
Note the following use of model-evaluation plots. Based on the residual plot, one could doubt the linearity and mean-variance independence assumptions of the Gaussian normal linear model, atleast given the amount of missing values. 

Plotting the best fit linear model grouped by `Suburb` we get (noting that we are warned of the missing values by ggplot)
```{r}
ggplot(data = subSuburb, mapping = aes(x = BuildingArea, y = Price, colour = Suburb)) +  geom_point() + geom_smooth(method = "lm")
```
suggesting that the model might benefit from having a `Suburb` intercept feature added. Also, one may note that slopes of the lines are very different within each of the classes. If this would still be the case after having properly dealt with missing values, one could consider employing a linear mixed model to analyse the data.

In accordance with exercise 1.4, we may add `Suburb` as a (non-random) intercept, evaluate the model using `summary` and check model assumptions using the commands
```{r}
PriceBuildAreaSuburb_lm <- lm(Price ~ BuildingArea + Suburb, data = subSuburb)
summary(PriceBuildAreaSuburb_lm)
Stdresplot(PriceBuildAreaSuburb_lm)
plot(PriceBuildAreaSuburb_lm)
```


Looking at the residual plot, we are somewhat more satisfied than we were before, though we see that the 'trumpet' shape on the higher tail of the fitted values has not gone yet. There also seems to be a misfit in the lower tail. The QQplot looks similar to the previous one, suggesting that the main concern with the normality assumption of the noise lies in the tails and is very possibly due to outliers.

Looking at the summary, we see that `Building area` is still significant, that the baseline intercept (incorporating Brunswick) is non-significant, and that the intercept offsets from Brunswick both are significant.

Describing the coefficient estimates that are presented in the summary, the `lm` function estimates that there is a baseline intercept of `r summary(PriceBuildAreaSuburb_lm)$coef[1,1]` corresponding to the price of a $0$ building area home. Next, the model estimates that for each unit increase in building area, the home is going to get `r summary(PriceBuildAreaSuburb_lm)$coef[1,2]` AUD more expensive. In addition, the model estimates that whatever a Brunswick home costs, a similarly sized home in Craigieburn will cost `r abs(summary(PriceBuildAreaSuburb_lm)$coef[1,3])` less while a Hawthorn home of a similar size will cost `r summary(PriceBuildAreaSuburb_lm)$coef[1,4]` AUD more than in Brunswick. 

In relation to 1.4b) of the many other features to add to the model, one could indeed decide to include the number of car spaces (which are recorded in the `Car` column). We may however note that the desirability (and thus the value added) of carspaces varies depending on how far the home is from amenities, public transport, job, schools and so on, as well as how many people are to live at the place. Thus, while having two car spaces as compared to one might be an added value for a two adult, two car household living far away from public transport, it will probably not be for a two adult household living close to public transport. Under this consideration, one could therefore consider adding `Car` as part of an interaction term. One could also consider colinearity between `Car` with other features (for example the already included `Suburb` and `BuildingArea`)

We may build a linear model that includes `Car`, if we so desire, can be done like so:
```{r}
PriceBuildAreaSuburbCar_lm <- lm(Price ~ BuildingArea + Suburb + Car, data = subSuburb)
summary(PriceBuildAreaSuburbCar_lm)
Stdresplot(PriceBuildAreaSuburbCar_lm)
plot(PriceBuildAreaSuburbCar_lm)
```

For answering exercise 1.5 we may reconstruct the `Price ~ BuildingArea + Suburb` model with data subsetted to filter out homes less than $5m^2$ and greater than $300$:
```{r}
subSuburb_OutLRem <- subSuburb %>% subset(BuildingArea>5 & BuildingArea <=300)
PriceBuildAreaSuburb_OutLRem_lm <- lm(Price ~ BuildingArea + Suburb, data = subSuburb_OutLRem)
summary(PriceBuildAreaSuburb_OutLRem_lm)
```
Looking at the above summary, and comparing it to the unsubsetted one, it is possible to evaluate the effect on the `lm` model estimate of the `sum(subSuburb$BuildingArea<=5 | subSuburb$BuildingArea>300,na.rm=T) =`r sum(subSuburb$BuildingArea<=5 | subSuburb$BuildingArea>300,na.rm=T)`` datapoints that are smaller than or equal to $5m^2$ or larger than $300.$
```{r}
sum(subSuburb$BuildingArea<=5 | subSuburb$BuildingArea>300,na.rm=T)
```
We see that the t-tests still produce the same conclusions regarding significance, though the `Building Area` slope estimate is lower than before, while the rest of the estimates are higher than previously.

Going back to the `Price ~ BuildingArea + Suburb + Car` formula, we may once again subset the data for the model. Using the resulting estimates we may predict the price of a $2$ car spaces $100m^2$ house in Hawthorn as follows 
```{r}
new <- data.frame(BuildingArea = 100, Type = "h", Suburb = "Hawthorn", Car = 2)
PriceBuildAreaSuburbCar_Out_lm <- lm(Price ~ BuildingArea + Suburb + Car, data = subSuburb_OutLRem)
predict(PriceBuildAreaSuburbCar_Out_lm, new)
```
The model thus predicts a price of `r predict(PriceBuildAreaSuburbCar_Out_lm, new)` AUD for such a house.

To get a $95\%$ confidence interval for the predicted value, we may use the following command 
```{r}
predict(PriceBuildAreaSuburbCar_Out_lm, newdata = new, interval = "confidence")
```










